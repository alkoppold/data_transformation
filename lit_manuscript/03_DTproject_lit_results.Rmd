---
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r results}

# This file contains the results: 
# ...


```


```{r results-load-data}
library(gsheet)
data_extract = gsheet2tbl('docs.google.com/spreadsheets/d/1In5IKFNKbVj4WJCawDu2xfr_0CJ3off3Nr5chBaoYYU/edit?gid=1869532958#gid=1869532958/')
data_extract

## Exclude some studies due to several reasons (listed where?)
doi_exclude_studies <- c(
  "10.1111/psyp.12456",
  "10.1016/j.neuroimage.2015.06.086",
  "10.1093/scan/nsaa074",
  "10.1017/S0033291712000359",
  "10.1038/mp.2011.66",
  "10.5665/sleep/32.1.19",
  "10.1080/10615806.2012.672976",
  "10.1093/scan/nsw181",
  "10.1093/scan/nsv122",
  "10.1016/j.brat.2018.09.003",
  "10.1111/psyp.13650",
  "10.1016/j.biopsych.2010.08.015",
  "10.1027/2151-2604/a000523",
  "10.1016/j.nlm.2014.03.008",
  "10.1101/lm.053902.123",
  "10.1080/02699931.2018.1500445",
  "10.1038/s41598-019-49751-4",
  "10.1093/scan/nsx148",
  "10.1016/j.neuroimage.2018.03.030",
  "10.1016/j.clinph.2019.04.010",
  "10.1037/xlm0000558",
  "10.1037/xge0000496",
  "10.1093/sleep/zsad209"
)

data_extract <- data_extract[!is.element(data_extract$doi, doi_exclude_studies), ]


```

# Prereg paragraph 

More precisely, this work has two overarching aims: 

First, to systematically assess reporting practices in human fear conditioning research regarding the use of data transformation procedures and examination of statistical assumptions, such as the normal distribution of residuals, and the handling of outliers during fear acquisition training throughout a systematic review of the literature. This aim is directly linked to the application of data transformation procedures, critical in ensuring these assumptions are met and outliers are effectively managed.

Second, to systematically extract data transformation procedures used in the field of human fear conditioning from the literature. These will serve as a basis for a subsequent study (separate Preregistration), in which we will comprehensively examine in a multiverse analysis how the identified data transformation procedures affect the distribution of the data and ultimately reliability and effect sizes.


# Analysis ideas
# circle plot
```{r circle-plot}
library(tidyverse)
library(data.table)
library(scico)  # For modern scientific color palettes

df <- data_extract %>% select(36:43)
n_total <- nrow(df)

# Step 1: Pivot to long format (no drop_na yet!)
df_long <- df %>%
  pivot_longer(cols = everything(), names_to = "measure", values_to = "transformation")

# Step 2: Calculate proportion of non-NA values BEFORE dropping NAs
measure_percent <- df_long %>%
  group_by(measure) %>%
  summarise(prop = mean(!is.na(transformation))) %>%
  mutate(measure_label = paste0(measure, " (", round(100 * prop, 1), "%)"))

# Step 3: Create label map
label_map <- setNames(measure_percent$measure_label, measure_percent$measure)

### change on label ""rc, sqrt (analysis 1); z (analysis 2)""
df_long <- df_long %>%
  # Separate on ";" into rows
  separate_rows(transformation, sep = ";") %>%
  # Remove the analysis part in parentheses
  mutate(transformation = str_trim(str_remove(transformation, "\\s*\\(.*?\\)")))

# Step 4: Now drop NAs and apply label map
df_long <- df_long %>%
  drop_na() %>%
  mutate(measure = label_map[measure])

counts <- df_long %>%
  count(measure, transformation, drop = F) #%>%
  #mutate(transformation = ifelse(is.na(transformation), "Missing", transformation))

df_wide <- counts %>%
  pivot_wider(names_from = measure, values_from = n, values_fill = 0) %>%
  mutate(ID = paste0("T", row_number())) %>%
  relocate(ID)

id_labels <- df_wide %>% select(ID, transformation)
id_named_vec <- setNames(id_labels$transformation, id_labels$ID)

d <- df_wide %>%
  pivot_longer(cols = -c(ID, transformation), names_to = "Measure", values_to = "Count") %>%
  filter(Count > 0) %>%
  mutate(Type = ifelse(Count > 1, "more than one study", "one study only"))

d <- setDT(d)
# Step: Create a unique transformation-to-ID mapping
id_order <- d[ , .SD[1], by = transformation][order(transformation)]$ID

# Apply it as the factor level order
d[, ID := factor(ID, levels = id_order)]
#d[, ID := factor(ID, levels = d[, .N, by = ID][order(N)]$ID)]
#d[, Measure := factor(Measure, levels = d[, .N, by = Measure][order(N)]$Measure)]
d[, Measure := factor(Measure, levels = sort(unique(Measure)))]
d[, Measure2 := as.numeric(Measure)]

# Modern, perceptually uniform color palette from scico
#pal1 <- scico(n = length(levels(d$Measure)), palette = "bilbao")
#pal1 <- scico::scico(n = length(levels(d$Measure)), palette = "batlow")
#pal1 <- scico::scico(n = length(levels(d$Measure)), palette = "berlin")
pal1 <- scico(n = length(levels(d$Measure)), palette = "roma")



ggplot(d, aes(x = ID, y = Measure2, color = Measure, shape = Type, group = ID)) +
  geom_line(alpha = 0.5, size = 0.8, color = "grey50") +   # softer connecting lines
  geom_point(size = 5, stroke = 1.2, fill = "white") +      # bigger points, white fill, clear outlines
  geom_hline(yintercept = 1:length(unique(d$Measure)), colour = "grey92", size = 0.3) +
  geom_vline(xintercept = 1:length(unique(d$ID)), colour = "grey92", size = 0.3) +
  geom_rect(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = 0.6, fill = "white", color = NA) +
  coord_polar() +
  scale_shape_manual(values = c(19, 21)) +
  scale_y_continuous(
    limits = c(0, length(unique(d$Measure)) + 1),
    breaks = 1:length(unique(d$Measure)),
    labels = levels(d$Measure)
  ) +
  scale_color_manual(values = pal1) +
  scale_x_discrete(labels = id_named_vec) +
  theme_minimal(base_size = 14, base_family = "Helvetica") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank(),
    legend.position = "right",
    legend.title = element_text(face = "bold", size = 13),
    legend.text = element_text(size = 12),
    plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
    plot.subtitle = element_text(size = 13, hjust = 0.5, color = "grey40"),
    panel.border = element_blank()
  ) +
  labs(
    #title = "Transformation Types by Measure and Study",
    #subtitle = paste0("Across ", n_total, " included studies"),
    x = NULL,
    y = NULL,
    shape = "Transformation count",
    color = paste0("Measure used in (% of ", n_total, " studies)")
  )

# Step 1: Calculate total counts per Measure
d[, total_measure_count := sum(Count), by = Measure]

# Step 2: Calculate percentage for each transformation within the measure
d[, pct := 100 * Count / total_measure_count]

# Step 3: Create a label with percentage rounded, e.g. "45%"
d[, pct_label := paste0(round(pct, digits = 1), "%")]

pal1 <- scico(n = length(levels(d$Measure)), palette = "lipari")
pal1 = rev(pal1)


# Step 4: Add geom_text to the plot, adjust position with nudge_x or nudge_y
ggplot(d, aes(x = ID, y = Measure2, color = Measure, shape = Type, group = ID)) +
  geom_line(alpha = 0.5, size = 0.8, color = "grey50") +
  geom_point(size = 5, stroke = 1.2, fill = "white") +
  geom_text(aes(label = pct_label), 
            size = 3, 
            color = "black", 
            nudge_x = 0.3, 
            nudge_y = 0, 
            show.legend = FALSE)  + 
  geom_hline(yintercept = 1:length(unique(d$Measure)), colour = "grey92", size = 0.3) +
  geom_vline(xintercept = 1:length(unique(d$ID)), colour = "grey92", size = 0.3) +
  geom_rect(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = 0.6, fill = "white", color = NA) +
  coord_polar() +
  scale_shape_manual(values = c(19, 21)) +
  scale_y_continuous(
    limits = c(0, length(unique(d$Measure)) + 1),
    breaks = 1:length(unique(d$Measure)),
    labels = levels(d$Measure)
  ) +
  scale_color_manual(values = pal1) +
  scale_x_discrete(labels = id_named_vec) +
  theme_minimal(base_size = 14, base_family = "Helvetica") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank(),
    legend.position = "right",
    legend.title = element_text(face = "bold", size = 13),
    legend.text = element_text(size = 12),
    plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
    plot.subtitle = element_text(size = 13, hjust = 0.5, color = "grey40"),
    panel.border = element_blank()
  ) +
  labs(
    x = NULL,
    y = NULL,
    shape = "Transformation count",
    color = paste0("Measure used in (% of ", n_total, " studies)")
  )

```


## To prepare in advance:

- add columns to the dataset: would have testing of assumptions been necessary?


## Aim 1: Analysis

Calculate reporting frequencies of
- precise statement if it was applied on a trial-level, averaged first asf.
- a rationale behind the data transformation
- assumption testing
- outlier and criterion
- open science practices?
- specific statistical models?

Maybe identify patterns across studies
- Do studies that report one data transformation aspect also report the others? -> e.g., if trial-level, then also rationale
-> possible plot: spider

## MÃ¶glicher Aufbau
### a. Descriptives (Replication? in Supplementary)
n_with_exclusions, n_female_total, age_mean_total, age_sd_total, mental health disorder exclusion, Was an individual level analysis conducted

```{r results-descriptives}

# Define a theme for pretty plots
lit_theme = theme(
  text = element_text(size = 10),
  axis.title.x = element_text(size = 16, face = "bold"),
  axis.title.y = element_text(size = 16, face = "bold"),
  axis.text.y = element_text(size = 12, face = "bold"),
  axis.text.x = element_text(size = 14, face = "bold"),
  axis.ticks.x = element_blank(),
  legend.position = "none",
  panel.border = element_blank(),
  panel.grid.minor = element_blank(),
  panel.grid.major = element_blank(),
  panel.background = element_blank(),
  axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
  axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'))


# Number of all participants

violin_n <- ggplot(aes(x = 1, y = n_with_exclusions), data = data_extract) +
  geom_violin(width = 0.5, scale = "width", fill = "#F7AEF8", alpha = 0.5) +  # Color the whole violin
  geom_boxplot(width = 0.1, color = "grey40", alpha = 0.2) +  # Transparent boxplot
  geom_jitter(width = 0.1, size = 2, alpha = 0.7, color = "#F7AEF8") +  # Individual points
  xlab("") +
  ylab("Number of participants") +
  scale_y_continuous(breaks = seq(0, 150, by = 25),
                     labels =  seq(0, 150, by = 25), limits = c(0, 150)) +
  lit_theme +
  theme(axis.text.x = element_blank(),
        axis.line.x = element_blank())



# Number of females

violin_female <- ggplot(aes(x = 1, y = n_female_total), data = data_extract) +
  geom_violin(width = 0.5, scale = "width", fill = "#B388EB", alpha = 0.5) +  
  geom_boxplot(width = 0.1, color = "grey40", alpha = 0.2) +  
  geom_jitter(width = 0.1, size = 2, alpha = 0.7, color = "#B388EB") +  
  xlab("") +
  ylab("Number of female participants") +
  scale_y_continuous(breaks = seq(0, 100, by = 25),
                     labels = seq(0, 100, by = 25), limits = c(0, 100)) +
  lit_theme +
  theme(axis.text.x = element_blank(),
        axis.line.x = element_blank())


# Mean age distribution

violin_age_mean <- ggplot(aes(x = 1, y = age_mean_total), data = data_extract) +
  geom_violin(width = 0.5, scale = "width", fill = "#8093F1", alpha = 0.5) +  
  geom_boxplot(width = 0.1, color = "grey40", alpha = 0.2) +  
  geom_jitter(width = 0.1, size = 2, alpha = 0.7, color = "#8093F1") +  
  xlab("") +
  ylab("Mean age of participants") +
  scale_y_continuous(breaks = seq(0, 50, by = 10),
                     labels = seq(0, 50, by = 10), limits = c(0, 50)) +
  lit_theme +
  theme(axis.text.x = element_blank(),
        axis.line.x = element_blank())


# SD Age distribution

violin_age_sd <- ggplot(aes(x = 1, y = age_sd_total), data = data_extract) +
  geom_violin(width = 0.5, scale = "width", fill = "#72DDF7", alpha = 0.5) +  
  geom_boxplot(width = 0.1, color = "grey40", alpha = 0.2) +  
  geom_jitter(width = 0.1, size = 2, alpha = 0.7, color = "#72DDF7") +  
  xlab("") +
  ylab("SD age of participants") +
  scale_y_continuous(breaks = seq(0, 12, by = 3),
                     labels = seq(0, 12, by = 3), limits = c(0, 12)) +
  lit_theme +
  theme(axis.text.x = element_blank(),
        axis.line.x = element_blank())


### Combine the plots using patchwork
combined_violin_descript_plot <- violin_n + violin_female + violin_age_mean + violin_age_sd +
  plot_layout(ncol = 4)

# Display the combined plot
combined_violin_descript_plot



```


```{r results-mental-health}

## Table the column with mental health info
table_health_info <- as.data.frame(table(data_extract[grep("mental.health.disorder", names(data_extract))]))
colnames(table_health_info) <- c("category", "count")


# Compute percentages
table_health_info$fraction <- table_health_info$count / sum(table_health_info$count)

# Compute the cumulative percentages (top of each rectangle)
table_health_info$ymax <- cumsum(table_health_info$fraction)

# Compute the bottom of each rectangle
table_health_info$ymin <- c(0, head(table_health_info$ymax, n=-1))

# Compute label position
table_health_info$labelPosition <- (table_health_info$ymax + table_health_info$ymin) / 2

# Compute a good label
table_health_info$label <- paste0(table_health_info$category, ": ", table_health_info$count)

# Create the plot
ggplot(table_health_info, aes(ymax = ymax, ymin = ymin, xmax = 4, xmin = 3, fill=category)) +
  geom_rect() +
  geom_label(x = 3.5, aes(y = labelPosition, label = label), size = 6) +
  scale_fill_brewer(palette = "Set2") +
  coord_polar(theta = "y") +
  xlim(c(2, 4)) +
  ggtitle("Mental health disorder exclusion?") +
  theme_void() +
  theme(legend.position = "none")


```


```{r results-individual-level-analysis}

## Table the column with individual level analysis info
table_ind_analysis <- data_extract[grep("individual.level.analysis", names(data_extract))]
table_ind_analysis <- table_ind_analysis[ ,1]
table_ind_analysis <- as.data.frame(table(table_ind_analysis))
colnames(table_ind_analysis) <- c("category", "count")


# Compute percentages
table_ind_analysis$fraction <- table_ind_analysis$count / sum(table_ind_analysis$count)

# Compute the cumulative percentages (top of each rectangle)
table_ind_analysis$ymax <- cumsum(table_ind_analysis$fraction)

# Compute the bottom of each rectangle
table_ind_analysis$ymin <- c(0, head(table_ind_analysis$ymax, n=-1))

# Compute label position
table_ind_analysis$labelPosition <- (table_ind_analysis$ymax + table_ind_analysis$ymin) / 2

# Compute a good label
table_ind_analysis$label <- paste0(table_ind_analysis$category, ": ", table_ind_analysis$count)

# Create the plot
ggplot(table_ind_analysis, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
  geom_rect() +
  geom_label(x = 3.5, aes(y = labelPosition, label = label), size = 6) +
  scale_fill_brewer(palette = "Set3") +
  coord_polar(theta = "y") +
  xlim(c(2, 4)) +
  ggtitle("Individual analysis included?") +
  theme_void() +
  theme(legend.position = "none")

```


### b. Assumption Checking (am Beispiel hier mit Normality)
- Welches Statistische Verfahren vorgeschaltet? 
- Mario konsultieren
eine Frage -> dann Sanky mit Antwort und Anzahl, Tina/Mana bars, doughnuts, lolli, waffle/heatmap e.g., Was the normal distribution checked?, If yes, how?, before/after, etc.
FRAGEN
- Was the normal distribution checked?
- Was the homoscedasticity checked?
- Was the sphericity checked?
- Was the independence of residuals checked?
- Was the linearity checked?
- Was the multicollinearity checked?

```{r results-assumptions}

# Select the data
data_assump <- data_extract[ , grep("Was.the", names(data_extract))]
names(data_assump) <- c("Normality","Homoscedasticity","Sphericity","Independence","Linearity","Mulitcollinearity")

# Reshape it from wide to long
data_assump <- data_assump %>%
  pivot_longer(cols = everything(), names_to = "Assumption", values_to = "Checked") %>%
  count(Assumption, Checked) %>%
  group_by(Assumption) %>%
  mutate(
    percent = n / sum(n),
    label = scales::percent(percent)
  )

# Factorize the assumptions and checked variable and reorder the levels (for a more intuitive order)
data_assump$Assumption <- as.factor(data_assump$Assumption)
data_assump$Assumption <- factor(data_assump$Assumption,
                                    levels = c("Normality","Homoscedasticity","Sphericity",
                                               "Independence","Linearity","Mulitcollinearity"))
data_assump$Checked <- as.factor(data_assump$Checked)
data_assump$Checked <- factor(data_assump$Checked,
                                    levels = c("not reported","not specified","yes",
                                               "dependent variable"))

ggplot(data_assump, aes(x = factor(Assumption), y = n, fill = Checked)) +
  geom_bar(stat = "identity") +
  scale_fill_viridis_d(option = "D", alpha = 0.95) +
  geom_text(aes(label = label), 
            position = position_stack(vjust = 0.5), 
            color = "white", size = 4, fontface = "bold") +
  labs(y = "n studies") +
  lit_theme +
  theme(axis.title.y = element_blank(),
        legend.position = "top")+
  coord_flip() 
  



```


### c. Transformation Practices
specification of data transformation method, rationale, was the transformation applied on trial or average level
the different data transformations (how many studies use raw data?)
```{r results-transformations}

### SCR
data_trans_scr <- data_extract[ ,c(40, 45, 47)]
names(data_trans_scr) <- c("scr_transf","rationale_di","appl_transf")

# Convert to long format
data_trans_scr <- data_trans_scr %>%
  make_long(scr_transf,rationale_di,appl_transf)

# Plot the Sankey diagram
ggplot(data_trans_scr, aes(x = x, 
                    next_x = next_x, 
                    node = node, 
                    next_node = next_node, 
                    label = factor(node))) +
  geom_sankey(flow.alpha = 0.7, aes(fill = factor(node))) +
  geom_sankey_label(size = 4, color = 1, fill = "white") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  scale_x_discrete(breaks = c("scr_transf","rationale_di","appl_transf"),
                   labels = c("Transformation", "Rationale", "Application level")) +
  lit_theme + 
  theme(axis.text.y = element_blank(),
                    axis.ticks.y = element_blank(),
                    axis.title.x = element_blank())


```


### d. Outlier Practices
outlier removal reported?, outlier criterion, outlier refer to
z.B. Barplots of how often outlier removal is reported
Compare frequencies of different criteria (e.g., +/-2SD vs. +/-3SD)

```{r results-outlier}

data_outlier <- data_extract %>%
  select(33:35) %>%
   rename(
    outlier_reported = `outlier.removal.reported..yes..no..this.refers.to.quantitative.measures.such.as....3SD.and.not.qualitative.ones..artifacts..zero.responses.`,
    outlier_scope = `outlier.refer.to..subjects..trials..both..NA..not.reported`,
    outlier_criterion = `outlier.criterion..e.g.......2SD..this.refers.to.quantitative.measures.such.as....2SD.and.not.qualitative.ones..artifacts..zero.responses.`) %>%
    filter(!if_all(everything(), ~ is.na(.) | . == ""))%>%
mutate(
    outlier_scope = ifelse(row_number() == 33, "not reported", outlier_scope)
  ) %>%
  make_long(outlier_reported, outlier_scope, outlier_criterion)%>%
  filter(!if_all(c(node), is.na))

# Sankey Plot Outliers
ggplot(data_outlier, aes(x = x, 
               next_x = next_x, 
               node = node, 
               next_node = next_node,
               fill = factor(node),
               label = node)) +
  geom_sankey(flow.alpha = 0.5, node.color = 1) +
  geom_sankey_label(size = 4, color = 1, fill = "white") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  lit_theme + 
  theme(axis.text.y = element_blank(),
                    axis.ticks.y = element_blank(),
                    axis.title.x = element_blank())


```


### e. Outcome Measures
Binary presence/absence analysis
pattern identifizieren
the use of different psychophysioligical outcomes?scr, emg 
dot-plot-simulation

```{r results-outcome-measures}
data_outcome_measure <- data_extract %>%
  select(36:43) %>%
  rename(
   #"HR" = HR (BPM)
   #"EMG orbicularis oculi" = EMG.orbicularis.oculi,
   #"EMG startle" = EMG.startle,
  ## "EYE tracking" = EYE.tracking,
   #"pupil size" = PUPIL.SIZE
  ) %>%
  filter(!if_all(everything(), ~ is.na(.) | . == "")) %>%
  mutate(id = row_number()) %>%  # Add ID if no group exists
  pivot_longer(
    cols = -id,
    names_to = "Measure",
    values_to = "Transformation"
  ) %>%
  drop_na(Transformation) %>%
  count(Measure, Transformation) %>%
  group_by(Measure) %>%
  mutate(
    percent = n / sum(n),
    label = scales::percent(percent)
  )

ggplot(data_outcome_measure, aes(x = factor(Measure), y = n, fill = Transformation)) +
  geom_bar(stat = "identity") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  geom_text(aes(label = label), 
            position = position_stack(vjust = 0.5), 
            color = "white", size = 4, fontface = "bold") +
  lit_theme +
  theme(#axis.text.y = element_blank(),
        #axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        #axis.title.y = element_blank(),
        legend.position = "top")+
  coord_flip()+
  labs(y = "n studies")

### add combinations of data transformations

```


### f. Statistical Models
Statistical model, Main statistical test, further specification
- Count and visualize test types (t-test, ANOVA, mixed models)
- Compare test choice across study types or transformation practices
- Association with whether assumptions were tested

```{r results-statistical-models}
data_stat_models <- data_extract %>%
  select(48:51) %>%
  rename(
    design = `Stastistical.model..within..between.or.mixed.design...e.g...paired.t.test...within..independent.t.test...between.`,
    `levels of largest within factor` = `If.within.or.mixed..how.many.within.factor.levels..of.largest.within.factor....e.g...two.different.CS.stimuli...two.within.factors.`,
    `statistical test`   = `Main.statistical.test..t.test..AN.C.OVA..correlation..regression..mixed.model..other..ask.Perplexity.ai.with.copy.pasting.info.from.the.method.section.`,
    details = `Main.statistical.test..further.specification..e.g...non.parametric.test...if.ANCOVA..centered.covariate...if.mixed.model..paste.formula.here..of.other..name.of.test..e.g..chi.squared..MANOVA.`
  ) %>%
    filter(!if_all(everything(), ~ is.na(.) | . == ""))%>%
  make_long(design, `levels of largest within factor`, `statistical test`, details)%>%
  filter(!if_all(c(node), is.na))

ggplot(data_stat_models, aes(x = x, 
               next_x = next_x, 
               node = node, 
               next_node = next_node,
               fill = factor(node),
               label = node)) +
  geom_sankey(flow.alpha = 0.5, node.color = 1) +
  geom_sankey_label(size = 4, color = 1, fill = "white") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  lit_theme + 
  theme(axis.text.y = element_blank(),
                    axis.ticks.y = element_blank(),
                    axis.title.x = element_blank())
```



## Aim 2: Prepare a list including all identified transformations per outcome measure

## Possible plots
### For frequencies:
- Doughnut
- Pie
- Waffle
- Lollipop
- heatmaps