---
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r results}

# This file contains the results: 
# ...


```


```{r results-load-data}
library(gsheet)
data_extract = gsheet2tbl('https://docs.google.com/spreadsheets/d/1In5IKFNKbVj4WJCawDu2xfr_0CJ3off3Nr5chBaoYYU/edit?gid=1511433069#gid=1511433069/')
data_extract

## Exclude some studies due to several reasons (listed where?)
doi_exclude_studies <- c(
  "10.1111/psyp.12456",
  "10.1016/j.neuroimage.2015.06.086",
  "10.1093/scan/nsaa074",
  "10.1017/S0033291712000359",
  "10.1038/mp.2011.66",
  "10.5665/sleep/32.1.19",
  "10.1080/10615806.2012.672976",
  "10.1093/scan/nsw181",
  "10.1093/scan/nsv122",
  "10.1016/j.brat.2018.09.003",
  "10.1111/psyp.13650",
  "10.1016/j.biopsych.2010.08.015",
  "10.1027/2151-2604/a000523",
  "10.1016/j.nlm.2014.03.008",
  "10.1101/lm.053902.123",
  "10.1080/02699931.2018.1500445",
  "10.1038/s41598-019-49751-4",
  "10.1093/scan/nsx148",
  "10.1016/j.neuroimage.2018.03.030",
  "10.1016/j.clinph.2019.04.010",
  "10.1037/xlm0000558",
  "10.1037/xge0000496",
  "10.1093/sleep/zsad209"
)

data_extract <- data_extract[!is.element(data_extract$doi, doi_exclude_studies), ]


```

# Prereg paragraph 

More precisely, this work has two overarching aims: 

First, to systematically assess reporting practices in human fear conditioning research regarding the use of data transformation procedures and examination of statistical assumptions, such as the normal distribution of residuals, and the handling of outliers during fear acquisition training throughout a systematic review of the literature. This aim is directly linked to the application of data transformation procedures, critical in ensuring these assumptions are met and outliers are effectively managed.

Second, to systematically extract data transformation procedures used in the field of human fear conditioning from the literature. These will serve as a basis for a subsequent study (separate Preregistration), in which we will comprehensively examine in a multiverse analysis how the identified data transformation procedures affect the distribution of the data and ultimately reliability and effect sizes.


# Analysis ideas
# circle plot
```{r circle-plot}
library(tidyverse)
library(data.table)
library(scico)  # For modern scientific color palettes

df <- data_extract %>% select(36:43)
n_total <- nrow(df)

# Step 1: Pivot to long format (no drop_na yet!)
df_long <- df %>%
  pivot_longer(cols = everything(), names_to = "measure", values_to = "transformation")

# Step 2: Calculate proportion of non-NA values BEFORE dropping NAs
measure_percent <- df_long %>%
  group_by(measure) %>%
  summarise(prop = mean(!is.na(transformation))) %>%
  mutate(measure_label = paste0(measure, " (", round(100 * prop, 1), "%)"))

# Step 3: Create label map
label_map <- setNames(measure_percent$measure_label, measure_percent$measure)

### change on label ""rc, sqrt (analysis 1); z (analysis 2)""
df_long <- df_long %>%
  # Separate on ";" into rows
  separate_rows(transformation, sep = ";") %>%
  # Remove the analysis part in parentheses
  mutate(transformation = str_trim(str_remove(transformation, "\\s*\\(.*?\\)")))

# Step 4: Now drop NAs and apply label map
df_long <- df_long %>%
  drop_na() %>%
  mutate(measure = label_map[measure])

counts <- df_long %>%
  count(measure, transformation, drop = F) #%>%
  #mutate(transformation = ifelse(is.na(transformation), "Missing", transformation))

df_wide <- counts %>%
  pivot_wider(names_from = measure, values_from = n, values_fill = 0) %>%
  mutate(ID = paste0("T", row_number())) %>%
  relocate(ID)

id_labels <- df_wide %>% select(ID, transformation)
id_named_vec <- setNames(id_labels$transformation, id_labels$ID)

d <- df_wide %>%
  pivot_longer(cols = -c(ID, transformation), names_to = "Measure", values_to = "Count") %>%
  filter(Count > 0) %>%
  mutate(Type = ifelse(Count > 1, "more than one study", "one study only"))

d <- setDT(d)
# Step: Create a unique transformation-to-ID mapping
id_order <- d[ , .SD[1], by = transformation][order(transformation)]$ID

# Apply it as the factor level order
d[, ID := factor(ID, levels = id_order)]
#d[, ID := factor(ID, levels = d[, .N, by = ID][order(N)]$ID)]
#d[, Measure := factor(Measure, levels = d[, .N, by = Measure][order(N)]$Measure)]
d[, Measure := factor(Measure, levels = sort(unique(Measure)))]
d[, Measure2 := as.numeric(Measure)]

# Modern, perceptually uniform color palette from scico
#pal1 <- scico(n = length(levels(d$Measure)), palette = "bilbao")
#pal1 <- scico::scico(n = length(levels(d$Measure)), palette = "batlow")
# pal1 <- scico::scico(n = length(levels(d$Measure)), palette = "berlin")
pal1 <- scico(n = length(levels(d$Measure)), palette = "roma")



ggplot(d, aes(x = ID, y = Measure2, color = Measure, shape = Type, group = ID)) +
  geom_line(alpha = 0.5, size = 0.8, color = "grey50") +   # softer connecting lines
  geom_point(size = 5, stroke = 1.2, fill = "white") +      # bigger points, white fill, clear outlines
  geom_hline(yintercept = 1:length(unique(d$Measure)), colour = "grey92", size = 0.3) +
  geom_vline(xintercept = 1:length(unique(d$ID)), colour = "grey92", size = 0.3) +
  geom_rect(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = 0.6, fill = "white", color = NA) +
  coord_polar() +
  scale_shape_manual(values = c(19, 21)) +
  scale_y_continuous(
    limits = c(0, length(unique(d$Measure)) + 1),
    breaks = 1:length(unique(d$Measure)),
    labels = levels(d$Measure)
  ) +
  scale_color_manual(values = pal1) +
  scale_x_discrete(labels = id_named_vec) +
  theme_minimal(base_size = 14, base_family = "Helvetica") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank(),
    legend.position = "right",
    legend.title = element_text(face = "bold", size = 13),
    legend.text = element_text(size = 12),
    plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
    plot.subtitle = element_text(size = 13, hjust = 0.5, color = "grey40"),
    panel.border = element_blank()
  ) +
  labs(
    #title = "Transformation Types by Measure and Study",
    #subtitle = paste0("Across ", n_total, " included studies"),
    x = NULL,
    y = NULL,
    shape = "Transformation count",
    color = paste0("Measure used in (% of ", n_total, " studies)")
  )

# Step 1: Calculate total counts per Measure
d[, total_measure_count := sum(Count), by = Measure]

# Step 2: Calculate percentage for each transformation within the measure
d[, pct := 100 * Count / total_measure_count]

# Step 3: Create a label with percentage rounded, e.g. "45%"
d[, pct_label := paste0(round(pct, digits = 1), "%")]

pal1 <- scico(n = length(levels(d$Measure)), palette = "lipari")
pal1 = rev(pal1)


# Step 4: Add geom_text to the plot, adjust position with nudge_x or nudge_y
ggplot(d, aes(x = ID, y = Measure2, color = Measure, shape = Type, group = ID)) +
  geom_line(alpha = 0.5, size = 0.8, color = "grey50") +
  geom_point(aes(size = pct), stroke = 1.2, fill = "white") +  # SIZE mapped to pct
  geom_hline(yintercept = 1:length(unique(d$Measure)), colour = "grey92", size = 0.3) +
  geom_vline(xintercept = 1:length(unique(d$ID)), colour = "grey92", size = 0.3) +
  geom_rect(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = 0.6, fill = "white", color = NA) +
  coord_polar() +
  scale_shape_manual(values = c(19, 21)) +
  scale_y_continuous(
    limits = c(0, length(unique(d$Measure)) + 1),
    breaks = 1:length(unique(d$Measure)),
    labels = levels(d$Measure)
  ) +
  scale_color_manual(values = pal1) +
  scale_size(range = c(2, 10), name = "Percentage within measure") +  # Dot size scale
  scale_x_discrete(labels = id_named_vec) +
  theme_minimal(base_size = 14, base_family = "Helvetica") +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank(),
    legend.position = "right",
    legend.title = element_text(face = "bold", size = 13),
    legend.text = element_text(size = 12),
    plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
    plot.subtitle = element_text(size = 13, hjust = 0.5, color = "grey40"),
    panel.border = element_blank()
  ) +
  labs(
    x = NULL,
    y = NULL,
    shape = "Transformation count",
    color = paste0("Measure used in (% of ", n_total, " studies)")
  )


```


```{r re-transf}
# reference for transformation type?
# Load required libraries
library(tidyverse)
library(scico)
library(forcats)
library(patchwork)

# Load the relevant data
df_ref <- data_extract %>% select(rationale_given = 45, rationale_type = 46)

# -------------------------
# PIE 1: Was a rationale reported?
# -------------------------
df_pie1 <- df_ref %>%
  count(response = rationale_given) %>%
  filter(!is.na(response) & response != "") %>%
  mutate(
    percent = n / sum(n),
    label = paste0(response, "\n", n, " (", percent(percent, accuracy = 1), ")"),
    ymax = cumsum(percent),
    ymin = lag(ymax, default = 0),
    label_pos = (ymin + ymax) / 2
  )

plot1 <- ggplot(df_pie1, aes(ymax = ymax, ymin = ymin, xmax = 1, xmin = 0, fill = response)) +
  geom_rect(color = "white") +
  geom_text(aes(x = 1.2, y = label_pos, label = label), size = 4.5, color = "black", fontface = "bold") +
  coord_polar(theta = "y") +
  xlim(c(-0.5, 1.5)) +
  scale_fill_scico_d(palette = "roma", direction = -1) +
  theme_void(base_family = "Helvetica") +
  theme(
    legend.position = "none",
    plot.title = element_text(size = 16, face = "bold", hjust = 0)
  ) +
  labs(title = "Was a Rationale for Transformation Reported?")

# -------------------------
# PIE 2: What kind of rationale (only for 'yes')
# -------------------------
df_pie2 <- df_ref %>%
  filter(tolower(rationale_given) == "yes", !is.na(rationale_type), rationale_type != "") %>%
  count(response = rationale_type) %>%
  mutate(
    percent = n / sum(n),
    label = paste0(response, "\n", n, " (", percent(percent, accuracy = 1), ")"),
    ymax = cumsum(percent),
    ymin = lag(ymax, default = 0),
    label_pos = (ymin + ymax) / 2
  )

plot2 <- ggplot(df_pie2, aes(ymax = ymax, ymin = ymin, xmax = 1, xmin = 0, fill = response)) +
  geom_rect(color = "white") +
  geom_text(aes(x = 1.2, y = label_pos, label = label), size = 4.5, color = "black", fontface = "bold") +
  coord_polar(theta = "y") +
  xlim(c(-0.5, 1.5)) +
  scale_fill_scico_d(palette = "roma", direction = -1) +
  theme_void(base_family = "Helvetica") +
  theme(
    legend.position = "none",
    plot.title = element_text(size = 16, face = "bold", hjust = 0)
  ) +
  labs(title = "What Kind of Rationale Was Given?")

# -------------------------
# Combine both plots
# -------------------------
plot1 / plot2 + plot_layout(heights = c(1, 1.2))


# Prepare data
df_bar1 <- df_ref %>%
  count(response = rationale_given) %>%
  filter(!is.na(response) & response != "") %>%
  mutate(
    percent = n / sum(n),
    label = paste0(" (", percent(round(percent, digits = 3)), ")"),
    response = fct_reorder(response, n)
  )

# Create modern bar plot
ggplot(df_bar1, aes(x = fct_rev(response), y = percent, fill = response)) +
  geom_col(width = 0.6, alpha = 0.9) +
  geom_text(aes(label = label), hjust = -0.1, size = 4.5, color = "gray20", fontface = "bold") +
  coord_flip() +
  scale_y_continuous(labels = percent_format(accuracy = 1), expand = expansion(mult = c(0, 0.2))) +
  scale_fill_scico_d(palette = "roma", direction = -1, guide = "none") +
  theme_classic(base_size = 15) +
  theme(
    axis.title = element_blank(),
    axis.text = element_text(color = "gray10"),
    plot.title = element_text(size = 16, face = "bold", hjust = 0)
  ) +
  labs(title = "Was a Rationale for Transformation Reported?")


```



```{r assumptions}

# Load libraries
library(tidyverse)
library(forcats)
library(data.table)
library(scico)
library(patchwork)

# Extract and rename relevant columns
df_check = data_extract %>% select(20:32, 52)

names(df_check) <- c(
  "normal_distribution",
  "normal_how",
  "normal_before_after",
  "homoscedasticity",
  "homoscedasticity_how",
  "sphericity",
  "sphericity_how",
  "independence of residuals",
  "independence_how",
  "linearity",
  "linearity_how",
  "multicollinearity",
  "multicollinearity_how",
  "statistical_test"
)

# -----------------------------
# Prepare data for pie charts
# -----------------------------
df_cake <- df_check %>% select(1, 4, 6, 10, 12, 14)

df_long <- df_cake %>%
  pivot_longer(cols = everything(), names_to = "assumption", values_to = "status") %>%
  group_by(assumption, status) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(assumption) %>%
  mutate(
    percent = count / sum(count),
    label = paste0(round(percent * 100, digits = 1), "%"),
    ymax = cumsum(percent),
    ymin = lag(ymax, default = 0),
    label_pos = (ymin + ymax) / 2
  )

# Function to create pie chart with outer label positions
create_pie <- function(var_name) {
  df_sub <- df_long %>% filter(assumption == var_name)
  
  ggplot(df_sub, aes(ymax = ymax, ymin = ymin, xmax = 1, xmin = 0, fill = status)) +
    geom_rect(color = "white") +
    geom_text(
      aes(x = 1.2, y = label_pos, label = label),
      size = 4, fontface = "bold", color = "black"
    ) +
    coord_polar(theta = "y") +
    xlim(c(-0.5, 1.5)) +
    scale_fill_scico_d(palette = "roma", direction = -1) +
    theme_void(base_family = "Helvetica") +
    theme(
      legend.position = "right",
      legend.title = element_text(face = "bold", size = 10),
      plot.title = element_text(face = "bold", hjust = 0.5, size = 13)
    ) +
    labs(
      fill = "Status",
      title = var_name
    )
}

# -----------------------------
# Create normal_distribution bar plot with percentages
# -----------------------------
plot_normal <- df_check %>%
  filter(!is.na(normal_distribution)) %>%
  count(normal_distribution) %>%
  mutate(percent = n / sum(n)) %>%
  ggplot(aes(x = fct_reorder(normal_distribution, n), y = n, fill = normal_distribution)) +
  geom_col(width = 0.7) +
  geom_text(aes(label = paste0(" (", round(percent * 100, digits = 1), "%)")), 
            hjust = -0.1, size = 3, fontface = "bold") +
  scale_fill_scico_d(palette = "roma", direction = -1) +
  coord_flip() +
  theme_minimal(base_family = "Helvetica") +
  theme(
    legend.position = "none",
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_blank(),
    axis.text = element_text(size = 12)
  ) +
  labs(title = "Was Normal Distribution tested?")
plot_normal
# -----------------------------
# Combine bar plot and pie charts
# -----------------------------
pies <- unique(df_long$assumption) %>% map(create_pie)
final_plot <- wrap_plots(plot_normal, wrap_plots(pies, ncol = 3), ncol = 1, heights = c(1.2, 2))

# Display
final_plot

pies[[1]] + pies[[2]] + pies[[3]] 


```

```{r sphericity}

# Load required libraries
library(tidyverse)
library(scales)
library(glue)
library(scico)
library(forcats)

# Filter and select relevant variables
df_rmanova <- data_extract %>%
  filter(`Main statistical test: further specification (e.g., non-parametric test), if ANCOVA: centered covariate?, if mixed model: paste formula here, of other: name of test (e.g. chi-squared, MANOVA)` == "rmANOVA") %>%
  select(sphericity_checked = 25, sphericity_how = 26) %>%
  drop_na(sphericity_checked)

# Total articles with rmANOVA
n_articles_rmANOVA <- nrow(df_rmanova)

# -------------------------------
# CAKE (PIE) PLOT: sphericity_checked
# -------------------------------
df_pie <- df_rmanova %>%
  count(response = sphericity_checked) %>%
  mutate(
    percent = n / sum(n),
    label = paste0(response, "\n", n, " (", percent(percent, accuracy = 1), ")"),
    ymax = cumsum(percent),
    ymin = lag(ymax, default = 0),
    label_pos = (ymin + ymax) / 2
  )

plot_cake <- ggplot(df_pie, aes(ymax = ymax, ymin = ymin, xmax = 1, xmin = 0, fill = response)) +
  geom_rect(color = "white") +
  geom_text(aes(x = 1.2, y = label_pos, label = label), size = 4.5, fontface = "bold", color = "black") +
  coord_polar(theta = "y") +
  xlim(c(-0.5, 1.5)) +
  scale_fill_scico_d(palette = "roma", direction = -1) +
  theme_void(base_family = "Helvetica") +
  theme(
    legend.position = "none",
    plot.title = element_text(size = 17, face = "bold", hjust = 0)
  ) +
  labs(title = "Was Sphericity Checked?")

# -------------------------------
# BAR PLOT: sphericity_how
# -------------------------------
df_bar <- df_rmanova %>%
  filter(!is.na(sphericity_how) & sphericity_how != "") %>%
  count(response = sphericity_how) %>%
  mutate(
    percent = n / n_articles_rmANOVA,
    response = fct_reorder(response, n)
  )

plot_bar <- ggplot(df_bar, aes(x = fct_rev(response), y = percent, fill = response)) +
  geom_col(width = 0.6, alpha = 0.9) +
  geom_text(aes(label = paste0(" (", percent(percent, accuracy = 1), ")")),
            hjust = -0.05, size = 4, color = "gray20") +
  coord_flip() +
  scale_y_continuous(labels = percent_format(accuracy = 1), expand = expansion(mult = c(0, 0.2))) +
  scale_fill_scico_d(palette = "roma", direction = -1, guide = "none") +
  theme_classic(base_size = 15) +
  theme(
    axis.title = element_blank(),
    axis.text.y = element_text(size = 13, color = "gray10"),
    axis.text.x = element_text(size = 12, color = "gray30"),
    plot.title = element_text(size = 17, face = "bold", hjust = 0),
    plot.subtitle = element_text(size = 14, color = "gray40", margin = margin(b = 10))
  ) +
  labs(
    title = "How Was Sphericity Checked?"
  )

# Display both plots
library(patchwork)
plot_cake / plot_bar + plot_layout(heights = c(1, 1.2))



```



## To prepare in advance:

- add columns to the dataset: would have testing of assumptions been necessary?


## Aim 1: Analysis

Calculate reporting frequencies of
- precise statement if it was applied on a trial-level, averaged first asf.
- a rationale behind the data transformation
- assumption testing
- outlier and criterion
- open science practices?
- specific statistical models?

Maybe identify patterns across studies
- Do studies that report one data transformation aspect also report the others? -> e.g., if trial-level, then also rationale
-> possible plot: spider

## Möglicher Aufbau
### a. Descriptives (Replication? in Supplementary)
n_with_exclusions, n_female_total, age_mean_total, age_sd_total, mental health disorder exclusion, Was an individual level analysis conducted

```{r results-descriptives}

# Define a theme for pretty plots
lit_theme = theme(
  text = element_text(size = 10),
  axis.title.x = element_text(size = 16, face = "bold"),
  axis.title.y = element_text(size = 16, face = "bold"),
  axis.text.y = element_text(size = 12, face = "bold"),
  axis.text.x = element_text(size = 14, face = "bold"),
  axis.ticks.x = element_blank(),
  legend.position = "none",
  panel.border = element_blank(),
  panel.grid.minor = element_blank(),
  panel.grid.major = element_blank(),
  panel.background = element_blank(),
  axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
  axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'))


# Number of all participants

violin_n <- ggplot(aes(x = 1, y = n_with_exclusions), data = data_extract) +
  geom_violin(width = 0.5, scale = "width", fill = "#F7AEF8", alpha = 0.5) +  # Color the whole violin
  geom_boxplot(width = 0.1, color = "grey40", alpha = 0.2) +  # Transparent boxplot
  geom_jitter(width = 0.1, size = 2, alpha = 0.7, color = "#F7AEF8") +  # Individual points
  xlab("") +
  ylab("Number of participants") +
  scale_y_continuous(breaks = seq(0, 150, by = 25),
                     labels =  seq(0, 150, by = 25), limits = c(0, 150)) +
  lit_theme +
  theme(axis.text.x = element_blank(),
        axis.line.x = element_blank())



# Number of females

violin_female <- ggplot(aes(x = 1, y = n_female_total), data = data_extract) +
  geom_violin(width = 0.5, scale = "width", fill = "#B388EB", alpha = 0.5) +  
  geom_boxplot(width = 0.1, color = "grey40", alpha = 0.2) +  
  geom_jitter(width = 0.1, size = 2, alpha = 0.7, color = "#B388EB") +  
  xlab("") +
  ylab("Number of female participants") +
  scale_y_continuous(breaks = seq(0, 100, by = 25),
                     labels = seq(0, 100, by = 25), limits = c(0, 100)) +
  lit_theme +
  theme(axis.text.x = element_blank(),
        axis.line.x = element_blank())


# Mean age distribution

violin_age_mean <- ggplot(aes(x = 1, y = age_mean_total), data = data_extract) +
  geom_violin(width = 0.5, scale = "width", fill = "#8093F1", alpha = 0.5) +  
  geom_boxplot(width = 0.1, color = "grey40", alpha = 0.2) +  
  geom_jitter(width = 0.1, size = 2, alpha = 0.7, color = "#8093F1") +  
  xlab("") +
  ylab("Mean age of participants") +
  scale_y_continuous(breaks = seq(0, 50, by = 10),
                     labels = seq(0, 50, by = 10), limits = c(0, 50)) +
  lit_theme +
  theme(axis.text.x = element_blank(),
        axis.line.x = element_blank())


# SD Age distribution

violin_age_sd <- ggplot(aes(x = 1, y = age_sd_total), data = data_extract) +
  geom_violin(width = 0.5, scale = "width", fill = "#72DDF7", alpha = 0.5) +  
  geom_boxplot(width = 0.1, color = "grey40", alpha = 0.2) +  
  geom_jitter(width = 0.1, size = 2, alpha = 0.7, color = "#72DDF7") +  
  xlab("") +
  ylab("SD age of participants") +
  scale_y_continuous(breaks = seq(0, 12, by = 3),
                     labels = seq(0, 12, by = 3), limits = c(0, 12)) +
  lit_theme +
  theme(axis.text.x = element_blank(),
        axis.line.x = element_blank())


### Combine the plots using patchwork
combined_violin_descript_plot <- violin_n + violin_female + violin_age_mean + violin_age_sd +
  plot_layout(ncol = 4)

# Display the combined plot
combined_violin_descript_plot



```


```{r results-mental-health}

## Table the column with mental health info
table_health_info <- as.data.frame(table(data_extract[grep("mental.health.disorder", names(data_extract))]))
colnames(table_health_info) <- c("category", "count")


# Compute percentages
table_health_info$fraction <- table_health_info$count / sum(table_health_info$count)

# Compute the cumulative percentages (top of each rectangle)
table_health_info$ymax <- cumsum(table_health_info$fraction)

# Compute the bottom of each rectangle
table_health_info$ymin <- c(0, head(table_health_info$ymax, n=-1))

# Compute label position
table_health_info$labelPosition <- (table_health_info$ymax + table_health_info$ymin) / 2

# Compute a good label
table_health_info$label <- paste0(table_health_info$category, ": ", table_health_info$count)

# Create the plot
ggplot(table_health_info, aes(ymax = ymax, ymin = ymin, xmax = 4, xmin = 3, fill=category)) +
  geom_rect() +
  geom_label(x = 3.5, aes(y = labelPosition, label = label), size = 6) +
  scale_fill_brewer(palette = "Set2") +
  coord_polar(theta = "y") +
  xlim(c(2, 4)) +
  ggtitle("Mental health disorder exclusion?") +
  theme_void() +
  theme(legend.position = "none")


```


```{r results-individual-level-analysis}

## Table the column with individual level analysis info
table_ind_analysis <- data_extract[grep("individual.level.analysis", names(data_extract))]
table_ind_analysis <- table_ind_analysis[ ,1]
table_ind_analysis <- as.data.frame(table(table_ind_analysis))
colnames(table_ind_analysis) <- c("category", "count")


# Compute percentages
table_ind_analysis$fraction <- table_ind_analysis$count / sum(table_ind_analysis$count)

# Compute the cumulative percentages (top of each rectangle)
table_ind_analysis$ymax <- cumsum(table_ind_analysis$fraction)

# Compute the bottom of each rectangle
table_ind_analysis$ymin <- c(0, head(table_ind_analysis$ymax, n=-1))

# Compute label position
table_ind_analysis$labelPosition <- (table_ind_analysis$ymax + table_ind_analysis$ymin) / 2

# Compute a good label
table_ind_analysis$label <- paste0(table_ind_analysis$category, ": ", table_ind_analysis$count)

# Create the plot
ggplot(table_ind_analysis, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
  geom_rect() +
  geom_label(x = 3.5, aes(y = labelPosition, label = label), size = 6) +
  scale_fill_brewer(palette = "Set3") +
  coord_polar(theta = "y") +
  xlim(c(2, 4)) +
  ggtitle("Individual analysis included?") +
  theme_void() +
  theme(legend.position = "none")

```


### b. Assumption Checking (am Beispiel hier mit Normality)
- Welches Statistische Verfahren vorgeschaltet? 
- Mario konsultieren
eine Frage -> dann Sanky mit Antwort und Anzahl, Tina/Mana bars, doughnuts, lolli, waffle/heatmap e.g., Was the normal distribution checked?, If yes, how?, before/after, etc.
FRAGEN
- Was the normal distribution checked?
- Was the homoscedasticity checked?
- Was the sphericity checked?
- Was the independence of residuals checked?
- Was the linearity checked?
- Was the multicollinearity checked?

```{r results-assumptions}

# Select the data
data_assump <- data_extract[ , grep("Was.the", names(data_extract))]
names(data_assump) <- c("Normality","Homoscedasticity","Sphericity","Independence","Linearity","Mulitcollinearity")

# Reshape it from wide to long
data_assump <- data_assump %>%
  pivot_longer(cols = everything(), names_to = "Assumption", values_to = "Checked") %>%
  count(Assumption, Checked) %>%
  group_by(Assumption) %>%
  mutate(
    percent = n / sum(n),
    label = scales::percent(percent)
  )

# Factorize the assumptions and checked variable and reorder the levels (for a more intuitive order)
data_assump$Assumption <- as.factor(data_assump$Assumption)
data_assump$Assumption <- factor(data_assump$Assumption,
                                    levels = c("Normality","Homoscedasticity","Sphericity",
                                               "Independence","Linearity","Mulitcollinearity"))
data_assump$Checked <- as.factor(data_assump$Checked)
data_assump$Checked <- factor(data_assump$Checked,
                                    levels = c("not reported","not specified","yes",
                                               "dependent variable"))

ggplot(data_assump, aes(x = factor(Assumption), y = n, fill = Checked)) +
  geom_bar(stat = "identity") +
  scale_fill_viridis_d(option = "D", alpha = 0.95) +
  geom_text(aes(label = label), 
            position = position_stack(vjust = 0.5), 
            color = "white", size = 4, fontface = "bold") +
  labs(y = "n studies") +
  lit_theme +
  theme(axis.title.y = element_blank(),
        legend.position = "top")+
  coord_flip() 
  



```


### c. Transformation Practices
specification of data transformation method, rationale, was the transformation applied on trial or average level
the different data transformations (how many studies use raw data?)
```{r results-transformations}

library(ggsankey)

### SCR
data_trans_scr <- na.omit(data_extract[ , c(40, 48, 45)])
names(data_trans_scr) <- c("scr_transf", "transf_level", "rationale_di")

# Extract SCR-relevant info from multi-measure cells and uniformly code
data_trans_scr <- data_trans_scr %>%
  mutate(transf_level = case_when(
    grepl("SCR: not reported", transf_level) ~ "not reported",
    grepl("SCR: trial-level", transf_level) ~ "trial-level",
    grepl("across trials", transf_level) ~ "trial-level",
    grepl("assume on trial-level", transf_level) ~ "trial-level",
    TRUE ~ transf_level  # keep original
  ))

# Convert to long format
data_trans_scr <- data_trans_scr %>%
  make_long(scr_transf, transf_level, rationale_di)

# data_trans_scr$node <- factor(data_trans_scr$node, levels = sort(unique(data_trans_scr$node)))


# Plot the Sankey diagram
ggplot(data_trans_scr, aes(x = x, 
                    next_x = next_x, 
                    node = node, 
                    next_node = next_node, 
                    label = factor(node))) +
  geom_sankey(flow.alpha = 0.7, aes(fill = factor(node))) +
  geom_sankey_label(size = 4, color = 1, fill = "white") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  scale_x_discrete(breaks = c("scr_transf", "transf_level", "rationale_di"),
                   labels = c("Transformation", "Level", "Rationale")) +
  ggtitle("SCR: Data Transformation Methods, Application Level and Reporting Rationale") +
  lit_theme + 
  theme(axis.text.y = element_blank(),
                    axis.ticks.y = element_blank(),
                    axis.title.x = element_blank(), 
        plot.title = element_text(size=18, face="bold"))

ggsave("datatransf_rationale_scr_sankey.png", width = 14, height = 8, dpi = 300)


### SCL
data_trans_scl <- na.omit(data_extract[ ,c(41, 48, 45)])
names(data_trans_scl) <- c("scl_transf", "transf_level", "rationale_di")

# Convert to long format
data_trans_scl <- data_trans_scl %>%
  make_long(scl_transf, transf_level, rationale_di)

# Plot the Sankey diagram
ggplot(data_trans_scl, aes(x = x, 
                    next_x = next_x, 
                    node = node, 
                    next_node = next_node, 
                    label = factor(node))) +
  geom_sankey(flow.alpha = 0.7, aes(fill = factor(node))) +
  geom_sankey_label(size = 4, color = 1, fill = "white") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  scale_x_discrete(breaks = c("scl_transf", "transf_level", "rationale_di"),
                   labels = c("Transformation", "Level", "Rationale")) +
  ggtitle("SCL: Data Transformation Methods, Application Level and Reporting Rationale") +
  lit_theme + 
  theme(axis.text.y = element_blank(),
                    axis.ticks.y = element_blank(),
                    axis.title.x = element_blank(),
        plot.title = element_text(size=18, face="bold"))

ggsave("datatransf_rationale_scl_sankey.png", width = 14, height = 8, dpi = 300)


### EMG Startle
data_trans_emg_startle <- na.omit(data_extract[ ,c(39, 48, 45)])
names(data_trans_emg_startle) <- c("emg_startle_transf", "transf_level", "rationale_di")

# Extract SCR-relevant info from multi-measure cells and uniformly code
data_trans_emg_startle <- data_trans_emg_startle %>%
  mutate(transf_level = case_when(
    grepl("Startle: not reported", transf_level) ~ "not reported",
    grepl("Startle: trial-level", transf_level) ~ "trial-level",
    grepl("FPS: trial-level", transf_level) ~ "trial-level",
    grepl("EMG: average-level", transf_level) ~ "average-level",
    grepl("across trials", transf_level) ~ "trial-level",
    grepl("SCR: trial-level", transf_level) ~ "not reported",
    TRUE ~ transf_level  # keep original
  ))

# Convert to long format
data_trans_emg_startle <- data_trans_emg_startle %>%
  make_long(emg_startle_transf, transf_level, rationale_di)

# Plot the Sankey diagram
ggplot(data_trans_emg_startle, aes(x = x, 
                    next_x = next_x, 
                    node = node, 
                    next_node = next_node, 
                    label = factor(node))) +
  geom_sankey(flow.alpha = 0.7, aes(fill = factor(node))) +
  geom_sankey_label(size = 4, color = 1, fill = "white") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  scale_x_discrete(breaks = c("emg_startle_transf", "transf_level", "rationale_di"),
                   labels = c("Transformation", "Level", "Rationale")) +
  ggtitle("EMG Startle: Data Transformation Methods, Application Level and Reporting Rationale") +
  lit_theme + 
  theme(axis.text.y = element_blank(),
                    axis.ticks.y = element_blank(),
                    axis.title.x = element_blank(),
        plot.title = element_text(size=18, face="bold"))

ggsave("datatransf_rationale_emgstartle_sankey.png", width = 14, height = 8, dpi = 300)


### EMG orbicularis oculi
data_trans_emg_orbic <- na.omit(data_extract[ ,c(38, 48, 45)])
names(data_trans_emg_orbic) <- c("emg_orbic_transf", "transf_level", "rationale_di")

# Convert to long format
data_trans_emg_orbic <- data_trans_emg_orbic %>%
  make_long(emg_orbic_transf, transf_level, rationale_di)

# Plot the Sankey diagram
ggplot(data_trans_emg_orbic, aes(x = x, 
                    next_x = next_x, 
                    node = node, 
                    next_node = next_node, 
                    label = factor(node))) +
  geom_sankey(flow.alpha = 0.7, aes(fill = factor(node))) +
  geom_sankey_label(size = 4, color = 1, fill = "white") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  scale_x_discrete(breaks = c("emg_orbic_transf", "transf_level", "rationale_di"),
                   labels = c("Transformation", "Level", "Rationale")) +
  ggtitle("EMG Orbicularis Oculi: Data Transformation Methods, Application Level and Reporting Rationale") +
  lit_theme + 
  theme(axis.text.y = element_blank(),
                    axis.ticks.y = element_blank(),
                    axis.title.x = element_blank(),
        plot.title = element_text(size=18, face="bold"))

ggsave("datatransf_rationale_emgorbic_sankey.png", width = 14, height = 8, dpi = 300)


### HR
data_trans_hr <- na.omit(data_extract[ ,c(36, 48, 45)])
names(data_trans_hr) <- c("hr_transf", "transf_level", "rationale_di")

# Convert to long format
data_trans_hr <- data_trans_hr %>%
  make_long(hr_transf, transf_level, rationale_di)

# Plot the Sankey diagram
ggplot(data_trans_hr, aes(x = x, 
                    next_x = next_x, 
                    node = node, 
                    next_node = next_node, 
                    label = factor(node))) +
  geom_sankey(flow.alpha = 0.7, aes(fill = factor(node))) +
  geom_sankey_label(size = 4, color = 1, fill = "white") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  scale_x_discrete(breaks = c("hr_transf", "transf_level", "rationale_di"),
                   labels = c("Transformation", "Level", "Rationale")) +
  ggtitle("HR (bpm): Data Transformation Methods, Application Level and Reporting Rationale") +
  lit_theme + 
  theme(axis.text.y = element_blank(),
                    axis.ticks.y = element_blank(),
                    axis.title.x = element_blank(),
        plot.title = element_text(size=18, face="bold"))

ggsave("datatransf_rationale_hr_sankey.png", width = 14, height = 8, dpi = 300)


### HRV
data_trans_hrv <- na.omit(data_extract[ ,c(37, 48, 45)])
names(data_trans_hrv) <- c("hrv_transf", "transf_level", "rationale_di")

# Convert to long format
data_trans_hrv <- data_trans_hrv %>%
  make_long(hrv_transf, transf_level, rationale_di)

# Plot the Sankey diagram
ggplot(data_trans_hrv, aes(x = x, 
                    next_x = next_x, 
                    node = node, 
                    next_node = next_node, 
                    label = factor(node))) +
  geom_sankey(flow.alpha = 0.7, aes(fill = factor(node))) +
  geom_sankey_label(size = 4, color = 1, fill = "white") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  scale_x_discrete(breaks = c("hrv_transf", "transf_level", "rationale_di"),
                   labels = c("Transformation", "Level", "Rationale")) +
  ggtitle("HRV: Data Transformation Methods, Application Level and Reporting Rationale") +
  lit_theme + 
  theme(axis.text.y = element_blank(),
                    axis.ticks.y = element_blank(),
                    axis.title.x = element_blank(),
        plot.title = element_text(size=18, face="bold"))

ggsave("datatransf_rationale_hrv_sankey.png", width = 14, height = 8, dpi = 300)


### Eye tracking
data_trans_eyetrack <- na.omit(data_extract[ ,c(42, 48, 45)])
names(data_trans_eyetrack) <- c("eyetrack_transf", "transf_level", "rationale_di")

# Convert to long format
data_trans_eyetrack <- data_trans_eyetrack %>%
  make_long(eyetrack_transf, transf_level, rationale_di)

# Plot the Sankey diagram
ggplot(data_trans_eyetrack, aes(x = x, 
                    next_x = next_x, 
                    node = node, 
                    next_node = next_node, 
                    label = factor(node))) +
  geom_sankey(flow.alpha = 0.7, aes(fill = factor(node))) +
  geom_sankey_label(size = 4, color = 1, fill = "white") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  scale_x_discrete(breaks = c("eyetrack_transf", "transf_level", "rationale_di"),
                   labels = c("Transformation", "Level", "Rationale")) +
  ggtitle("Eye tracking: Data Transformation Methods, Application Level and Reporting Rationale") +
  lit_theme + 
  theme(axis.text.y = element_blank(),
                    axis.ticks.y = element_blank(),
                    axis.title.x = element_blank(),
        plot.title = element_text(size=18, face="bold"))

ggsave("datatransf_rationale_eyetrack_sankey.png", width = 14, height = 8, dpi = 300)


### Pupil size
data_trans_pupil <- na.omit(data_extract[ ,c(43, 48, 45)])
names(data_trans_pupil) <- c("pupil_transf", "transf_level", "rationale_di")

# Convert to long format
data_trans_pupil <- data_trans_pupil %>%
  make_long(pupil_transf, transf_level, rationale_di)

# Plot the Sankey diagram
ggplot(data_trans_pupil, aes(x = x, 
                    next_x = next_x, 
                    node = node, 
                    next_node = next_node, 
                    label = factor(node))) +
  geom_sankey(flow.alpha = 0.7, aes(fill = factor(node))) +
  geom_sankey_label(size = 4, color = 1, fill = "white") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  scale_x_discrete(breaks = c("pupil_transf", "transf_level", "rationale_di"),
                   labels = c("Transformation", "Level", "Rationale")) +
  ggtitle("Pupil size: Data Transformation Methods, Application Level and Reporting Rationale") +
  lit_theme + 
  theme(axis.text.y = element_blank(),
                    axis.ticks.y = element_blank(),
                    axis.title.x = element_blank(),
        plot.title = element_text(size=18, face="bold"))

ggsave("datatransf_rationale_pupil_sankey.png", width = 14, height = 8, dpi = 300)

```


### d. Outlier Practices
outlier removal reported?, outlier criterion, outlier refer to
z.B. Barplots of how often outlier removal is reported
Compare frequencies of different criteria (e.g., +/-2SD vs. +/-3SD)

```{r results-outlier}

library(dplyr)
library(stringr)

### Outlier removal methods
data_outlier <- data_extract %>%
  select(33:35) %>%
   rename_with(~ c("outlier_reported", "outlier_scope", "outlier_criterion"), everything()) %>%
    filter(!if_all(everything(), ~ is.na(.) | . == ""))

# previous code scrap: check why this row was changed
# mutate(
#     outlier_scope = ifelse(row_number() == 34, "not reported", outlier_scope))
  
# Group outlier categories 
data_outlier_grouped <- data_outlier %>%
  mutate(
    outlier_criterion_group = case_when(
      str_detect(outlier_criterion, regex("\\bSD\\b", ignore_case = TRUE)) ~ "SD-based threshold (e.g., ± 3 SD)",
      str_detect(outlier_criterion, regex("\\bZ\\b")) ~ "Z-based threshold (e.g., Z > 3)",
      str_detect(outlier_criterion, regex("IQR", ignore_case = TRUE)) ~ "IQR-based threshold (e.g., > Q3 + 1.5*IQR)",
      str_detect(outlier_criterion, regex("Mahalanobis|Grubbs|correlation", ignore_case = TRUE)) ~ "statistical tests (e.g., Mahalanobis distance, Smirmov–Grubbs)",
      str_detect(outlier_criterion, "visual inspection") ~ "manual visual inspection",
      str_detect(outlier_criterion, regex("not reported", ignore_case = TRUE)) ~ "not reported",
      is.na(outlier_criterion) ~ NA_character_,
      TRUE ~ "other"
    )
  )

# Convert to long format
data_outlier_grouped_long <- data_outlier_grouped%>%
  make_long(outlier_reported, outlier_scope, outlier_criterion_group) %>%
  filter(!if_all(c(node), is.na))

### Outlier removal: Sankey Plot 
ggplot(data_outlier_grouped_long, aes(x = x, 
               next_x = next_x, 
               node = node, 
               next_node = next_node,
               fill = factor(node),
               label = node)) +
  geom_sankey(flow.alpha = 0.5, node.color = 1) +
  geom_sankey_label(size = 4, color = 1, fill = "white") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  scale_x_discrete(breaks = c("outlier_reported", "outlier_scope", "outlier_criterion_group"),
                   labels = c("Outlier removal reported?", "Scope", "Criterion")) +
  ggtitle("Outlier Removal: Reporting Practices, Scope and Outlier Criterion") +
  lit_theme + 
  theme(axis.text.y = element_blank(),
                    axis.ticks.y = element_blank(),
                    axis.title.x = element_blank(), 
        plot.title = element_text(size=18, face="bold"))

ggsave("outlier_removal_sankey.png", width = 14, height = 8, dpi = 300)


# Group the outlier criterion thresholds by type (SD-, IQR- or Z-based)
data_outlier_grouped_plots <- data_outlier_grouped %>%
  mutate(
    cutoff_value = case_when(
      outlier_criterion_group == "IQR-based threshold (e.g., > Q3 + 1.5*IQR)" ~ str_extract(outlier_criterion, "\\d+(\\.\\d+)?(?=\\*IQR)"),
      outlier_criterion_group %in% c("SD-based threshold (e.g., ± 3 SD)", "Z-based threshold (e.g., Z > 3)") ~ str_extract(outlier_criterion, "\\d+(\\.\\d+)?"),
      TRUE ~ NA_character_
    ),
    cutoff_value = as.numeric(cutoff_value)
  ) %>%
  filter(!is.na(cutoff_value))  # Keep only valid cutoffs


### Barplot of individual outlier criterion thresholds
ggplot(data_outlier_grouped_plots, aes(x = factor(cutoff_value), fill = outlier_criterion_group)) +
  geom_bar(position = "stack") +
  labs(
    title = "Most Common Outlier Thresholds by Criterion Type",
    x = "Threshold Value", y = "Count", fill = "Criterion Group") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  lit_theme + 
  theme(axis.title.x = element_blank(), 
        plot.title = element_text(size=18, face="bold"), 
        legend.position = "right",
        legend.text = element_text(size = 12),         
        legend.title = element_text(size = 14, face = "bold"))
  
ggsave("outlier_removal_thresholds_barplot.png", width = 14, height = 8, dpi = 300)

```


### e. Outcome Measures
Binary presence/absence analysis
pattern identifizieren
the use of different psychophysioligical outcomes?scr, emg 
dot-plot-simulation

```{r results-outcome-measures}
data_outcome_measure <- data_extract %>%
  select(36:43) %>%
  rename(
   #"HR" = HR (BPM)
   #"EMG orbicularis oculi" = EMG.orbicularis.oculi,
   #"EMG startle" = EMG.startle,
  ## "EYE tracking" = EYE.tracking,
   #"pupil size" = PUPIL.SIZE
  ) %>%
  filter(!if_all(everything(), ~ is.na(.) | . == "")) %>%
  mutate(id = row_number()) %>%  # Add ID if no group exists
  pivot_longer(
    cols = -id,
    names_to = "Measure",
    values_to = "Transformation"
  ) %>%
  drop_na(Transformation) %>%
  count(Measure, Transformation) %>%
  group_by(Measure) %>%
  mutate(
    percent = n / sum(n),
    label = scales::percent(percent)
  )

ggplot(data_outcome_measure, aes(x = factor(Measure), y = n, fill = Transformation)) +
  geom_bar(stat = "identity") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  geom_text(aes(label = label), 
            position = position_stack(vjust = 0.5), 
            color = "white", size = 4, fontface = "bold") +
  lit_theme +
  theme(#axis.text.y = element_blank(),
        #axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        #axis.title.y = element_blank(),
        legend.position = "top")+
  coord_flip()+
  labs(y = "n studies")

### add combinations of data transformations

```


### f. Statistical Models
Statistical model, Main statistical test, further specification
- Count and visualize test types (t-test, ANOVA, mixed models)
- Compare test choice across study types or transformation practices
- Association with whether assumptions were tested

```{r results-statistical-models}
data_stat_models <- data_extract %>%
  select(48:51) %>%
  rename(
    design = `Stastistical.model..within..between.or.mixed.design...e.g...paired.t.test...within..independent.t.test...between.`,
    `levels of largest within factor` = `If.within.or.mixed..how.many.within.factor.levels..of.largest.within.factor....e.g...two.different.CS.stimuli...two.within.factors.`,
    `statistical test`   = `Main.statistical.test..t.test..AN.C.OVA..correlation..regression..mixed.model..other..ask.Perplexity.ai.with.copy.pasting.info.from.the.method.section.`,
    details = `Main.statistical.test..further.specification..e.g...non.parametric.test...if.ANCOVA..centered.covariate...if.mixed.model..paste.formula.here..of.other..name.of.test..e.g..chi.squared..MANOVA.`
  ) %>%
    filter(!if_all(everything(), ~ is.na(.) | . == ""))%>%
  make_long(design, `levels of largest within factor`, `statistical test`, details)%>%
  filter(!if_all(c(node), is.na))

ggplot(data_stat_models, aes(x = x, 
               next_x = next_x, 
               node = node, 
               next_node = next_node,
               fill = factor(node),
               label = node)) +
  geom_sankey(flow.alpha = 0.5, node.color = 1) +
  geom_sankey_label(size = 4, color = 1, fill = "white") +
  scale_fill_viridis_d(option = "A", alpha = 0.95) +
  lit_theme + 
  theme(axis.text.y = element_blank(),
                    axis.ticks.y = element_blank(),
                    axis.title.x = element_blank())
```



## Aim 2: Prepare a list including all identified transformations per outcome measure

## Possible plots
### For frequencies:
- Doughnut
- Pie
- Waffle
- Lollipop
- heatmaps