---
title: "Outtakes_data_transformations"
author: "Maren Klingelh√∂fer-Jens"
date: "2024-03-13"
output: html_document
---

```{r data-transformations}

# # Log-transform the raw data
# data_long$scr_log <- log10(1+data_long$scr_raw)
# 
# # Square root transform the raw data
# data_long$scr_sqr <- sqrt(data_long$scr_raw)
# 
# # Box cox transform the data: the added positive constant is the smallest raw SCR within the data set
# b <- boxcox(lm(data_long$scr_raw - min(data_long$scr_raw) + 1 ~ 1), plotit=F)
# # Extract lambda
# lambda <- b$x[which.max(b$y)]
# lambda
# data_long$scr_box <- (data_long$scr_raw ^ lambda - 1)/lambda
# 
# # z transform the data
# data_long$scr_ztr <- scale(data_long$scr_raw)[,1] #[,1] to get rid of M and SD which is also returned


#######################################################################################################################
### Prepare range correction by calculating max SCR of CS and US responses
# Max amplitude CS
# data_long$scr_max_cs <- NA
# for (i in unique(data_long$id)) {
#   data_select <- data_long[which(data_long$id == i & grep("^cs", data_long$stimulus)), ]
#   max_ampl_cs <- max(data_select$scr_raw, na.rm = T)
#   data_long$scr_max_cs[which(data_long$id == i)] <- max_ampl_cs
# }
# 
# # Max amplitude US
# data_long$scr_max_us <- NA
# for (i in unique(data_long$id)) {
#   data_select <- data_long[which(data_long$id == i & grep("ucs", data_long$stimulus)), ]
#   max_ampl_us <- max(data_select$scr_raw, na.rm = T)
#   data_long$scr_max_us[which(data_long$id == i)] <- max_ampl_us
# }
# 
# 
# ### Range correct all transformation types with CS-rc
# data_long$scr_raw_rc_cs <- data_long$scr_raw/data_long$scr_max_cs
# data_long$scr_log_rc_cs <- data_long$scr_log/data_long$scr_max_cs #TODO this also divides by the max raw value but should be max log value?
# data_long$scr_sqr_rc_cs <- data_long$scr_sqr/data_long$scr_max_cs
# data_long$scr_box_rc_cs <- data_long$scr_box/data_long$scr_max_cs
# data_long$scr_ztr_rc_cs <- data_long$scr_ztr/data_long$scr_max_cs
# 
# ### Range correct all transformation types with US-rc
# data_long$scr_raw_rc_us <- data_long$scr_raw/data_long$scr_max_us
# data_long$scr_log_rc_us <- data_long$scr_log/data_long$scr_max_us
# data_long$scr_sqr_rc_us <- data_long$scr_sqr/data_long$scr_max_us
# data_long$scr_box_rc_us <- data_long$scr_box/data_long$scr_max_us
# data_long$scr_ztr_rc_us <- data_long$scr_ztr/data_long$scr_max_us

######################################################################################################################

### Add CS discrimination
# Select data and calculate CS discrimination
# data_cs_dis <- data_long[grep("cspe|csm", data_long$stimulus), ]
# data_cs_dis <- spread(data_cs_dis, stimulus, scr_raw)
# data_cs_dis$csd <- data_cs_dis$cspe - data_cs_dis$csm
# 
# # Reshape data back to wide format
# data_cs_dis <- gather(data_cs_dis, stimulus, scr_raw, csm:csd, factor_key = TRUE)
# 
# # Melt it with US responses in data_long
# data_long <- rbind(data_cs_dis, data_long[grep("ucs", data_long$stimulus) , ])

```


```{r descriptives}

# Select CS+ responses
# data_CSP <- data_long %>% filter(stimulus=="csp")
# 
# # Exclude max SCR
# #data_CSP <- data_CSP[ ,-grep("_max_", names(data_CSP))]
# 
# # Convert data from wide to long and delete condition column as well as stimulus columns
# #data_CSP <- gather(data_CSP, key = "approach", value = "scr_mean", - c(id, trialnr, stimulus, stim_cat))
# data_CSP = data_CSP %>% mutate(approach = paste(transformation, range_cor, sep="_")) %>% rename(scr_mean = scr_raw)
# data_CSP <- data_CSP[ ,-grep("stimulus", names(data_CSP))]
# 
# # Factorize approach
# data_CSP$approach <- as.factor(data_CSP$approach)
# 
# # Delete box cox, looks strange...
# #data_CSP <- data_CSP[-grep("box", data_CSP$approach), ]

data_CSP <- data_long %>% filter(stimulus=="csp") %>% 
  mutate(approach = paste(transformation, range_cor, sep="_") %>% as_factor()) %>% 
  rename(scr_mean = scr)


# Summarise within transformations (means and SEMs)
rm(data_triallevel)
data_triallevel = data_CSP %>%
  group_by(trialnr, approach) %>%
  summarise(scr.mean = mean(as.numeric(scr_mean), na.rm = T), 
            scr.sem = sd(as.numeric(scr_mean), na.rm = T)/sqrt(length(scr_mean))) #not correct if missing values

# Add confidence intervals to the dataframe (95%)
data_triallevel$lower <- data_triallevel$scr.mean - 1.96*data_triallevel$scr.sem
data_triallevel$upper <- data_triallevel$scr.mean + 1.96*data_triallevel$scr.sem
n_data = length(unique(data_old$id))

#### LINEPLOT: different transformations
gp2 <- ggplot(data_triallevel, aes(x=trialnr, y=scr.mean, colour=approach, group=approach)) +
   geom_point(aes(group=approach), size=2) +
  
  # Add lines between points
  geom_line(aes(group=approach), size=1.2) +
  # Add CI
  geom_ribbon(aes(ymin=lower, ymax=upper, fill=approach, color=NULL), alpha=0.2) +
  
  scale_x_continuous(breaks = scales::pretty_breaks()) + #integer breaks
  # Title of axes
  xlab("Acquisition trials") +
  ylab("SCR") +
  # Title of the whole plot can be added here
  ggtitle("") +
  # Add number of participants as text in plot
  annotate("text", x = 8, y = .8, label = paste("n =", n_data), size = 6) +
  # Settings for fonts, ticks, legend and background of the plot
  theme(plot.title = element_text(size=20, face="bold", hjust=0.5),
        axis.text.x = element_text(size=16, face="bold", color="black"),
        axis.text.y = element_text(size=16, face="bold", color="black"), 
        axis.title.x = element_text(size=20, face="bold"),
        axis.title.y = element_text(size=20, face="bold", margin=margin(0,10,0,0)),
        legend.title = element_text(size=16, face="bold"),
        legend.text = element_text(size=16),
        legend.key = element_blank(),
        axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1),
        axis.ticks.x=element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())

gp2

```

```{r specification-curve}

### Transformations

# loading the original data 
#X7163CM_8163CM_EDA_ac <- read_sav("data/7163CM_8163CM_EDA_ac.sav")
  
# in long format 
load("./data/long_EDA_merz.Rdata")

# Rename some variables
names(data_long)[grep("Versuchspersonennummer", names(data_long))] <- "id"
names(data_long)[grep("scr", names(data_long))] <- "scr_raw"

### Add different transformations
# Log-transform the raw data
data_long$scr_log <- log10(1+data_long$scr_raw)

# Square root transform the raw data
data_long$scr_sqr <- sqrt(data_long$scr_raw)

# Box cox transform the data: the added positive constant is the smallest raw SCR wihtin the data set
b <- boxcox(lm(0.009995+data_long$scr_raw ~ 1))
# Extract lambda
lambda <- b$x[which.max(b$y)]
lambda
data_long$scr_box <- (data_long$scr_raw ^ lambda - 1)/lambda

# z transform the data
data_long$scr_ztr <- scale(data_long$scr_raw)


### Prepare range correction by calculating max SCR of CS and US responses
# Max amplitude CS
data_long$scr_max_cs <- NA
for (i in unique(data_long$id)) {
  data_select <- data_long[which(data_long$id == i & grep("_cs", data_long$condition)), ]
  max_ampl_cs <- max(data_select$scr_raw, na.rm = T)
  data_long$scr_max_cs[which(data_long$id == i)] <- max_ampl_cs
}

# Max amplitude US
data_long$scr_max_us <- NA
for (i in unique(data_long$id)) {
  data_select <- data_long[which(data_long$id == i & grep("_uc", data_long$condition)), ]
  max_ampl_us <- max(data_select$scr_raw, na.rm = T)
  data_long$scr_max_us[which(data_long$id == i)] <- max_ampl_us
}


### Range correct all transformation types with CS-rc
data_long$scr_raw_rc_cs <- data_long$scr_raw/data_long$scr_max_cs
data_long$scr_log_rc_cs <- data_long$scr_log/data_long$scr_max_cs
data_long$scr_sqr_rc_cs <- data_long$scr_sqr/data_long$scr_max_cs
data_long$scr_box_rc_cs <- data_long$scr_box/data_long$scr_max_cs
data_long$scr_ztr_rc_cs <- data_long$scr_ztr/data_long$scr_max_cs

### Range correct all transformation types with US-rc
data_long$scr_raw_rc_us <- data_long$scr_raw/data_long$scr_max_us
data_long$scr_log_rc_us <- data_long$scr_log/data_long$scr_max_us
data_long$scr_sqr_rc_us <- data_long$scr_sqr/data_long$scr_max_us
data_long$scr_box_rc_us <- data_long$scr_box/data_long$scr_max_us
data_long$scr_ztr_rc_us <- data_long$scr_ztr/data_long$scr_max_us

############################################################################################################

### Calculate t-tests, effect sizes asf (NHST)
data <- gather(data_long, key = "approach", value = "scr_mean", - c(id,condition, trialnr, stimulus ))
data <- data %>% filter(approach != "scr_max_cs") # this is not a transformation procedure 
data <- data %>% filter(approach != "scr_max_us")


res_ttest_means <- data %>% filter(stimulus %in% c('cspe', 'csm')) %>%
  group_by(approach) %>%
  summarise(scr_mean_csp = mean(scr_mean[stimulus == 'cspe'], na.rm = T),
            scr_mean_csm = mean(scr_mean[stimulus == 'csm'], na.rm = T),
            scr_sd_csp = sd(scr_mean[stimulus == 'cspe'], na.rm = T),
            scr_sd_csm = sd(scr_mean[stimulus == 'csm'], na.rm = T))
  
# t test; select csp and csm 
res_ttest <- data %>% filter(stimulus %in% c('cspe', 'csm')) %>%
  group_by(approach) %>%
  rstatix::t_test(scr_mean ~ stimulus, data = ., paired = T) 


# effect size (using Hedges G)
res_ttest_g <- data %>% filter(stimulus %in% c('cspe', 'csm')) %>%
  group_by(approach) %>%
rstatix::cohens_d(scr_mean ~ stimulus, data = .,paired = T,ci = T,hedges.correction = TRUE)

### For positive Cohen's d: convert ESs and CIs to absolute values
res_ttest_g$effsize <- abs(res_ttest_g$effsize)
res_ttest_g$conf.low <- abs(res_ttest_g$conf.low)
res_ttest_g$conf.high <- abs(res_ttest_g$conf.high)

# add index to order by effect size
# we have n + 1 unique approaches
res_ttest_g$approach_num <-  1:nrow(res_ttest_g)
res_ttest_g[order(res_ttest_g$effsize),'approach_eff_order'] <-  1:nrow(res_ttest_g)

### Add columns for transformation (log, sqrt, box cox, z-transformation) and range correction type (none, CS corrected, US corrected)
res_ttest_g$transf_type <- str_split_fixed(res_ttest_g$approach, "_", 3)[,2]
res_ttest_g$rc_type <- str_split_fixed(res_ttest_g$approach, "_", 3)[,3]
res_ttest_g$rc_type[res_ttest_g$rc_type == ""] <- "none"


###############################################################################################################
### BAYESIAN PART ####
appr_list <- names(data_long)[grep("^scr_", names(data_long))]
appr_list <- appr_list[appr_list != "scr_max_cs" & appr_list != "scr_max_us"]
n_appr = length(appr_list)

#*****
n_its <- 1000  # number of iterations, should this be 1000000? Then I run into problems, too big.
res_tBF <- list(approach = NA, 
                ttest_BF = NA,
                ttest_BF_post = NA) 


for(ind in 1:n_appr){
  # extract name of approach
  appr <- appr_list[ind]
  
  # build dummy dataframe with one approach only
  dat_dummy <- data %>% 
    filter(stimulus %in% c('cspe','csm')) %>%
    filter(approach == appr)
  
  # copmute BF (note: when using the formula notation, paired does not work)
  #bf <- ttestBF(formula = scr_mean ~ stimType, data = dat_dummy, paired = T)
  bf <- ttestBF(dat_dummy$scr_mean[dat_dummy$stimulus == 'cspe'], 
                dat_dummy$scr_mean[dat_dummy$stimulus == 'csm'], paired = T)
  bf_post <- posterior(bf, iterations = n_its) 
  
  # put in dataframe
  res_tBF$approach[ind] <- appr
  res_tBF$ttest_BF[ind] <- list(bf)
  res_tBF$ttest_BF_post[ind] <- list(bf_post)
  
}



# extract relevant information from list, build empty dataframe
results_BF_effsize <- data.frame(approach = NA,
                                 approach_num = NA,
                                 effsize = NA,
                                 effsize_low =NA,
                                 effsize_upp = NA,
                                 BF_ln = NA)

for (ind in 1:n_appr){
  results_BF_effsize[ind, 'approach'] <- as.character(res_tBF$approach[ind])
  results_BF_effsize[ind, 'approach_num'] <- ind
  # extract effect size and 95% interval around effect size
  results_BF_effsize[ind,'effsize'] <- median(res_tBF$ttest_BF_post[[ind]][,'delta'])
  # extract CI around estimate
  results_BF_effsize[ind, 'effsize_low'] <- summary(res_tBF$ttest_BF_post[[ind]])$quantiles['delta',][1]
  results_BF_effsize[ind, 'effsize_upp'] <-summary(res_tBF$ttest_BF_post[[ind]])$quantiles['delta',][5]
  # add log BF
  results_BF_effsize[ind, 'BF_ln'] <- res_tBF$ttest_BF[[ind]]@bayesFactor[['bf']]
}

# add parameters seperately
results_BF_effsize$approach <- factor(results_BF_effsize$approach)
# this is not optimal:
results_BF_effsize <- merge(results_BF_effsize, data.frame(res_ttest[1:5]))

# add column for ordered effect sizes
results_BF_effsize[order( results_BF_effsize$effsize),'approach_eff_order'] <-  1:nrow(results_BF_effsize)

```

```
#### Added by Marta: old calculations

``` {r old: reliability across stimuli (stratified), eval=F}
data_wide = data_long %>% mutate(condition = paste(transformation, range_cor, sep="_"),
                                 condition = condition %>% gsub("_none", "", .) %>% gsub("_", "_rc_", .)) %>% 
  pivot_wider(names_from=condition, values_from=scr, id_cols=c(id, trialnr, stimulus))
reliabilities.strat.permutations = tibble(
  raw = reliability_helper(data_wide, fn_score_mean("raw"), replications, stratification="stimulus"),
  log = reliability_helper(data_wide, fn_score_mean("log"), replications, stratification="stimulus"),
  sqr = reliability_helper(data_wide, fn_score_mean("sqr"), replications, stratification="stimulus"),
  box = reliability_helper(data_wide, fn_score_mean("box"), replications, stratification="stimulus"),
  ztr = reliability_helper(data_wide, fn_score_mean("ztr"), replications, stratification="stimulus"),
  
  raw_rc_cs = reliability_helper(data_wide, fn_score_mean("raw_rc_cs"), replications, stratification="stimulus"),
  log_rc_cs = reliability_helper(data_wide, fn_score_mean("log_rc_cs"), replications, stratification="stimulus"),
  sqr_rc_cs = reliability_helper(data_wide, fn_score_mean("sqr_rc_cs"), replications, stratification="stimulus"),
  box_rc_cs = reliability_helper(data_wide, fn_score_mean("box_rc_cs"), replications, stratification="stimulus"),
  ztr_rc_cs = reliability_helper(data_wide, fn_score_mean("ztr_rc_cs"), replications, stratification="stimulus"),
  
  raw_rc_us = reliability_helper(data_wide, fn_score_mean("raw_rc_us"), replications, stratification="stimulus"),
  log_rc_us = reliability_helper(data_wide, fn_score_mean("log_rc_us"), replications, stratification="stimulus"),
  sqr_rc_us = reliability_helper(data_wide, fn_score_mean("sqr_rc_us"), replications, stratification="stimulus"),
  box_rc_us = reliability_helper(data_wide, fn_score_mean("box_rc_us"), replications, stratification="stimulus"),
  ztr_rc_us = reliability_helper(data_wide, fn_score_mean("ztr_rc_us"), replications, stratification="stimulus")
)
reliabilities.strat = reliabilities.strat.permutations %>% 
  summarise(across(.fns=list(m = fnFishZ, sd = ~ fnFishZ(.x, fn=sd)), 
            .cols=everything(), .names="{.col}_x_{.fn}")) %>% 
  pivot_longer(cols=everything()) %>% separate(col=name, into=c("method", "metric"), sep="_x_") %>% 
  pivot_wider(names_from = "metric", id_cols = "method") %>% arrange(desc(m))
reliabilities.strat
```





#### Krippendorf's alpha

```{r krippendorfs}
# use the function by Zapf to also extract confidence intervals, using bootstrapping
source('./scripts/Zapf_Krip_alpha_function.R')

# set number of bootstrapping, should be 1000, but reduce for testing code
n_boots <- 10
save_fig = 'yes'
x_lab <- expression(paste('Krippendorff\'s ',alpha))
y_lab <- 'all together'
```

```{r kripp-prep}
# loop through dataframes that only contain one trial (ie.unique cs type and number)

# remove TTP approach (i.e, 10) from dat: approach %in% 1:9
# remove approach 9 (i.e, SCL) for visualisation: approach %in% 1:8 for suppl
dat <- data_long [c(1,3:8)]
dat2 <- dat %>%
  pivot_longer(cols = -c(id, trialnr, stimulus), 
               names_to = "approach", 
               values_to = "scr") 
  
  
# split into different dataframes
# 42 acquistition trials

dat_split_per_trial <- dat2 %>%
  dplyr::select(id, approach, stimulus, trialnr, scr) %>% # changed this to scr instead of scr_log_r
  group_split(stimulus,trialnr)

# build dataframe for extracted data
ka_df <- data.frame(trial = NA,
                    kaZ_rank = NA, 
                    kaZ_rank_lc = NA,
                    kaZ_rank_uc = NA)

# loop through 48 trials (118 subjects * 9 methods = 1380 observations per df)
for (ind in 1:48){
  df <- dat_split_per_trial[[ind]] # trial 1, csm
  
  # dataframe for kripp alpha function from Zapf et al 2016
  df_2 <- df %>% pivot_wider(names_from = approach, 
                             values_from = scr, 
                             names_prefix = 'approach') %>% # changed this to scr instead of scr_log_r
    dplyr::select(-c(id,stimulus,trialnr)) %>%
    as.matrix()
  
  # compute, note nboot is 10 statt 1000, sonst dauert das ewig!
  k_zapf_rank <- k_alpha(df_2, scaling = 'ordinal', nboot = n_boots)
  
  # print(paste(df$cs[1], df$number_cs[1], sep = '_'))
  ka_df[ind,'cs'  ] <-  df$stimulus[1]
  ka_df[ind,'trial'  ] <-  paste(df$stimulus[1], df$trialnr[1], sep = '_')
  ka_df[ind, 'kaZ_rank'] <- k_zapf_rank$est.alpha
  ka_df[ind, 'kaZ_rank_lc'] <- k_zapf_rank$ci.boot.alpha[1]
  ka_df[ind, 'kaZ_rank_uc'] <- k_zapf_rank$ci.boot.alpha[2]
  
}
#print values , does the fucntion kable() work here?           
knitr::kable(ka_df) 
```

```{r update-str-df-ka-avg}
# update structure of ka_df
ka_df$trial <- factor(ka_df$trial, levels = ka_df$trial)
ka_df$stimType <- sub('_([^_]*)$','', ka_df$trial)
```


```{r build-plot-ka-avg}
# plot
p_kA <- ggplot(ka_df, aes(x = kaZ_rank, y = trial, color = stimType)) +
  geom_point(aes(x = kaZ_rank),size = 5) +
  geom_errorbarh(aes(xmin = kaZ_rank_lc, xmax = kaZ_rank_uc), height = 0, size = 1.5) +
  #scale_color_manual(name = NULL, values = c('blue','red','black'), labels = c('CS -', 'CS +', 'US'), guide = guide_legend(reverse=TRUE)) +
  xlim(0,1) +
  xlab(x_lab) +
  ylab(y_lab) +
  scale_y_discrete(labels = c('CS_M_1' = '1', 'CS_M_14' = '14',
                              'CS_P_1' = '1', 'CS_P_14' = '14',
                              'US_1' = '1', 'US_14' = '14'), 
                   breaks = c('CS_M_1', 'CS_M_14', 'CS_P_1', 'CS_P_14',
                              'US_1', 'US_14')) +
  # add benchmarks
  geom_vline(xintercept = c(.4, .6, .8), linetype = 'longdash') +
  # add label for benchmarks
  annotate('text', x = .45, y = 42, label = 'fair') +
  annotate('text', x = .65, y = 42, label = 'moderate') +
  annotate('text', x = .85, y = 42, label = 'perfect') +
  theme_classic() +
  theme(text = element_text(size=28), 
        legend.position = "right" ) #c(.90, .25)
p_kA
```

#### Pairwise (i.e, approach wise) comparisons of Krippendorff's alpha

```{r estimate-ka-pairwise}
# loop through dataframes that only contain one trial (ie.unique cs type and number)

# split into different dataframes
# 42 acquistition trials
dat_split_per_trial <- dat2 %>%
  dplyr::select(id, approach, stimulus, trialnr, scr) %>%
  group_split(stimulus,trialnr)

# build dataframe for extracted data
ka_df <- data.frame(trial = NA,
                    stimType= NA,
                    kaZ_rank = NA, 
                    kaZ_rank_lc = NA,
                    kaZ_rank_uc = NA,
                    app_x = NA,
                    app_y = NA)
ka_df_pw <- ka_df

# loop through 42 trials (118 subjects * 10 methods = 1180 observations per df, if no NAs in TTP)
for (ind in 1:48){
  df <- dat_split_per_trial[[ind]] # trial 1, csm
  df$approach = as.factor(df$approach)
  # select combinations
  for(app_x in 1:(nlevels(df$approach)-1)){
    for(app_y in (app_x+1):nlevels(df$approach)){
      
      # select 2 approaches to compare, for every subject there are 2 values for the 2 approaches specific stimulus type at this trial, i.e., ideally 118 * 2 values
      df_xy <- df %>%
        filter(approach %in% c(app_x, app_y)) %>%
        droplevels()
      
      
      # dataframe for kripp alpha function from Zapf et al 2016
      df_2 <- df %>% pivot_wider(names_from = approach, 
                                    values_from = scr, 
                                    names_prefix = 'approach') %>%
        dplyr::select(-c(id,stimulus,trialnr)) %>%
        as.matrix()
      
      # compute, adjust nboot to save time
      # note for all 45 approach comparisons, I set nboot = 1 which does not make sense   for calc a confidence interval off course, bc only 1 value is estimated
      # for 45 (unique approach combinations) and 42 trial = 1890 estimations, this took approx 20 mins to run
      k_zapf_rank <- k_alpha(df_2, scaling = 'ordinal', nboot = n_boots)
      
      # 
      # print(paste(df$cs[1], df$number_cs[1], sep = '_'))
      
      ka_df$trial <-  paste(df$stimulus[1], df$trialnr[1], sep = '_')
      ka_df$stimType <- as.character(df$stimulus[1])
      ka_df$kaZ_rank <- k_zapf_rank$est.alpha
      ka_df$kaZ_rank_lc <- k_zapf_rank$ci.boot.alpha[1]
      ka_df$kaZ_rank_uc <- k_zapf_rank$ci.boot.alpha[2]
      ka_df$app_x <- app_x
      ka_df$app_y <- app_y
      
      # put in one large dataframe
      ka_df_pw <- rbind(ka_df_pw, ka_df)
      
    }
  }
}
#print values , does the fucntion kable() work here?           
#kable(ka_df) 

Sys.time()
```

```{r update-str-df}
ka_df_pw <- ka_df_pw[-1, ]  # first row were NAs
ka_df_pw$stimType <- as.factor(ka_df_pw$stimType)
ka_df_pw$trial <- factor(ka_df_pw$trial, levels = unique(ka_df_pw$trial))
ka_df_pw$trial_nr <- factor(gsub('^.*_','',ka_df_pw$trial), levels = 1:14)
#ka_df_pw$app_x <- factor(ka_df_pw$app_x, levels = unique(ka_df_pw$app_x))
#ka_df_pw$app_y <- factor(ka_df_pw$app_y, levels = unique(ka_df_pw$app_y))
```

Now plot Kripp alpha for always two approaches separately for all stimulus types.

```{r settings-plot}
lim_x <- c(-1,1)  # most accurate
lim_x <- c(-.3,1)  # for better data visualisation
```

```{r build-plot-ka-pairwise}
# rename approach 10 to TTP, to avoid confusion
ka_df_pw[ka_df_pw$app_x == 1, 'app_x'] <- 'box'
ka_df_pw[ka_df_pw$app_x == 2, 'app_x'] <- 'log'
ka_df_pw[ka_df_pw$app_x == 3, 'app_x'] <- 'raw'
ka_df_pw[ka_df_pw$app_x == 4, 'app_x'] <- 'sqrt'

ka_df_pw[ka_df_pw$app_y == 1, 'app_y'] <- 'box'
ka_df_pw[ka_df_pw$app_y == 2, 'app_y'] <- 'log'
ka_df_pw[ka_df_pw$app_y == 3, 'app_y'] <- 'raw'
ka_df_pw[ka_df_pw$app_y == 4, 'app_y'] <- 'sqrt'

# start with splitting the df per comparison
ka_per_comp <- ka_df_pw %>% 
  group_split(app_x, app_y) 

# 45 comparisons: 9 BLC approaches, 1 TTP method
for (ind in 1:6){
 df_temp <- ka_per_comp[[ind]] %>%
   data.frame()

 plot_ind <- df_temp %>%
   ggplot(aes(x = kaZ_rank, y = trial, color = stimType)) +
   geom_point(aes(x = kaZ_rank)) +
   geom_errorbarh(aes(xmin = kaZ_rank_lc, xmax = kaZ_rank_uc), height = 0.5) +
   #scale_color_manual(values = c('blue','red','black')) +
   scale_y_discrete(labels = c('CS_M_1' = '1','CS_M_14' = '14',
                              'CS_P_1' = '1','CS_P_14' = '14',
                              'US_1' = '1','US_14' = '14'), 
                   breaks = c('CS_M_1','CS_M_14','CS_P_1','CS_P_14',
                              'US_1','US_14')) +
    # add benchmarks
  geom_vline(xintercept = c(.4, .6, .8), linetype = 'longdash') +
   scale_x_continuous(n.breaks = 3, limits = lim_x) +
   ggtitle(paste0(df_temp$app_x[1], ' vs ', df_temp$app_y[1])) +
   xlab(x_lab) +
   theme_classic() +
   theme(legend.position = "none",
         text = element_text(size=16) ) +
   theme(axis.title = element_blank())
 plot_ind
   # temporary without legend for matrix arrangement

assign(paste('plot_ind',ind, sep = '_'), plot_ind)
}

# combine plots using a matrix
plot_mat <- matrix(nrow = 3, ncol = 3, byrow = T)
plot_ind <- upper.tri(plot_mat, diag = T)

plot_mat[plot_ind] <- c(1,2,3,4,5,6)
#paste0('plot_ind_',1:45,collapse = ',')
plot_list <- list(plot_ind_1,plot_ind_2,plot_ind_3,plot_ind_4,plot_ind_5,plot_ind_6)

# fill matrix with plots
plot_upp_tri <- gridExtra::grid.arrange(grobs = plot_list, layout_matrix = plot_mat) 
```

```{r save-plot-ka-pairwise}
# save plot
if (save_fig == 'yes'){
png(paste0('figures/fig_', '_krippalph_tranf.png'), units="in", width=24, height=24, res=300)
plot(plot_upp_tri)
dev.off()
}
```

```{r arrange-ka-plots}
# arrangement with patchwork

# make list of all plots to be plotted
 plot_list_2 <- c(plot_list, list(p_kA))

 # build index of letters for layout of design "matrix"
 letter_ind <- c(rbind(letters[1:3], LETTERS[1:3]))


# plot and add labels
plot_combined <-  wrap_plots(plot_list_2) +
  plot_layout(tag_level = 'new') 
  #plot_annotation(tag_levels = list(c('B', rep('', 4), 'A')))
plot_combined


```


```{r alinas-code-specification-curve-between}

########################################################################################## ALINAS CODE
# order by effect size
# colored by approach
p1 <- merged_datasets %>%
  ggplot(aes(x = approach_eff_order, y = effsize, color = dataset)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
#  scale_color_manual(name = 'Transformation', values = clrs[c(1:5)], labels = c("box cox", "log-transformed", "none", "square-root", "z-transformed")) +
 # scale_x_continuous(breaks = c(1:15), labels = c(1:15)) +
  theme_classic() +
  theme(text = element_text(size=size_text),
        legend.position = 'top') +
  xlab(x_lab) +
  ylab(y_lab) + 
  guides(color = guide_legend(nrow = 1))


# plot specifications of parameters
s1 <- ggplot(merged_datasets, aes(x = approach_eff_order, y = transf_type)) +
  geom_point(shape = '|', size = size_point) +
   #scale_color_manual(values = rep('black', length(levels(res_ttest_d$approach)) )) +
  scale_y_discrete(name = 'Dataset') +
    #scale_x_continuous(breaks = c(1:15), labels = c(1:15)) +
  theme(axis.text.x = element_blank(),
        axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        panel.background = element_blank(),
        legend.position = 'none') +
  theme(text = element_text(size=size_text)) 
s1

# Combine plots

plot_spec_NHST <- p1 / s1
plot_spec_NHST

```
