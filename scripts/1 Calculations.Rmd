---
title: "Task_Force_Descriptives"
author: "Alina Koppold"
date: "2023-11-08"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(haven)
library(MASS)
library(splithalfr)
library(tidyverse)
```

```{r helpers}
boxcoxvec = function(x, min=1) { #cf. scales::boxcox_trans()
  if (min %>% is.numeric()) x = x - min(x, na.rm=T) + min
  lambda = MASS::boxcox(x ~ 1, plotit=F) %>% 
    bind_cols() %>% filter(y == max(y)) %>% pull(x) %>% mean()
  return((x ^ lambda - 1) / lambda)
}

prune = function(x, low=-Inf, high=+Inf, abs=NA) {
  result = if_else(x < low, low, x) %>% if_else(. > high, high, .)
  if (abs %>% is.na() == F) result = if_else(abs(result) > abs, abs * if_else(result > 0, 1, -1), result)
  return(result)
}

reliability_helper = function(data, fn_score, replications, #need to be specified
                              participants="id", stratification=NULL, #constant for one data set
                              fn_coef=splithalfr::spearman_brown, ncores=parallel::detectCores() - 1, careful=F, verbose=F) #sensible defaults
{
  if (stratification %>% is.null() == F) stratification = data %>% pull(!!stratification)
  splithalfr::by_split(data=data, fn_score=fn_score, replications=replications,
                       participants = data %>% pull(!!participants), 
                       stratification = stratification,
                       ncores=ncores, careful=careful, verbose=verbose) %>% 
    splithalfr::split_coefs(fn_coef=fn_coef)
}

fn_score_mean = function(column, na.rm=T) { #idea: create a function that
  return(function(df) { #returns another function 
    return(mean(dplyr::pull(df, !!column), na.rm=na.rm)) #with specifications (column & na.rm) from the parent-function => parameter df gets filled inside by_split function call
    #note: this would not be needed if by_split had a "..." argument that gets passed into fn_score
    
    #return(df %>% pull(!!column) %>% mean(na.rm=na.rm)) #requires library(tidyverse) for parallel (inefficient)
  })
}

rToFishZ = function(r) { return(.5*log((1+r)/(1-r))) }
fishZtoR = function(Z) { return(ifelse(Z==Inf, 1, (exp(2*Z)-1)/(exp(2*Z)+1))) }
fnFishZ = function(r, fn=mean, prune=.999, ...) { 
  warning.txt = ""
  if (any(abs(r) >= 1, na.rm=T)) {
    warning.txt = "Correlation(s) contain(s) values at or beyond 1. This will bias results for summary functions." %>% paste0(warning.txt, .)
    if (prune %>% is.na()) warning = "Consider setting prune parameter." %>% paste(warning.txt, .)
    else {
      warning.txt = paste0("Pruning to ", prune, ".") %>% paste(warning.txt, .)
      
      r = r %>% prune(abs=prune) #if_else(abs(r) >= 1, prune * if_else(r > 0, 1, -1), r)
    }
    warning(warning.txt)
  }
  
  return(r %>% rToFishZ() %>% fn(...) %>% fishZtoR()) 
}
```

```{r data}
# loading the original data 
data_long = haven::read_sav("data/Merz.sav") %>% rename(id = Versuchspersonennummer) %>% 
  pivot_longer(-id, names_to = "condition", values_to = "scr_raw") %>% 
  separate(condition, into=c(NA, NA, NA, "stimulus", "trialnr"), sep="_") %>% 
  mutate(trialnr = trialnr %>% str_extract("\\d+") %>% as.integer()) %>% 
  
  filter(stimulus %in% c("cspe", "csm", "ucs")) %>% #only keep responses to CS+ (will be extinguished), CS-, and UCS
  mutate(stimulus = if_else(stimulus == "cspe", "csp", stimulus), #rename cspe to csp for generalizability to other data sets
         stim_cat = if_else(stimulus %>% startsWith("cs"), "cs", "ucs")) %>% #option to calculate boxcox across CS- and CS+
  select(id, trialnr, stimulus, stim_cat, scr_raw) #reorder
```

```{r transformations}
# Log-transform the raw data
data_long = data_long %>% 
  mutate(scr_log = log10(1+scr_raw),
         scr_sqr = sqrt(scr_raw)) %>% 
  
  # group_by(stimulus) %>% mutate(scr_shift = scr_raw - min(scr_raw) + 1, 
  #                               lambda = boxcox(scr_shift ~ 1, plotit=F) %>% 
  #                                 bind_cols() %>% filter(y == max(y)) %>% pull(x) %>% mean()) %>% ungroup() %>% 
  # mutate(scr_box_check = (scr_shift ^ lambda - 1) / lambda) %>% 
  group_by(stimulus) %>% mutate(scr_box = boxcoxvec(scr_raw)) %>% ungroup() %>% 
  
  #group_by(id) %>% #this implicitly invokes something similar to a range correction => don't do it? How is it used in the literature?
  mutate(scr_ztr = scale(scr_raw)[,1],
         scr_ztr = scr_ztr - min(scr_ztr)) #make sure that minimum response is 0 (and not negative)

#View(data_long)
#data_long %>% ggplot(aes(x = scr_raw, y = scr_box, color = stimulus)) + geom_point() + theme_bw()
#data_long %>% filter(transformation %>% grepl("box", .)) %>% pivot_wider(names_from=transformation, values_from=scr) %>% filter(scr_box != scr_box_check)

data_long = data_long %>% 
  #select(-scr_shift, -lambda) %>% #remove helping variables
  pivot_longer(starts_with("scr_"), names_to = "transformation", values_to = "scr")
```

```{r range correction}
# Prepare range correction by calculating max SCR of CS and US responses
data_long.max = data_long %>% 
  summarise(scr_max = max(scr, na.rm=T), .by = c(id, stim_cat, transformation)) %>% 
  pivot_wider(names_from = stim_cat, names_prefix = "max_", values_from = scr_max, id_cols = c("id", "transformation"))

data_long.max %>% summarise(across(starts_with("max"), list("min" = min, "max" = max)))
#some participant's max response is negative (probably due to z-transform across all participants, i.e., their max is still below the group average)
# => absolute value of minimum has been "added" to shift z-scored values to a minimum of 0

data_long.max %>% filter(max_cs == 0 | max_ucs == 0)
#subject 446: only zero responses to CSs

data_long.max = data_long.max %>% mutate(across(starts_with("max_"), function(x) {if_else(x == 0, Inf, x)})) #replace 0 with Inf (such that scr / Inf == 0)

data_long = data_long %>% full_join(data_long.max) %>% 
  mutate(scr_rc_cs = scr / max_cs,
         scr_rc_us = scr / max_ucs) %>% 
         #stimulus = if_else(stimulus %>% is.na(), "ucs", stimulus) %>% as_factor()) %>% 
  select(-starts_with("max_")) %>% rename(scr_rc_none = scr) %>% 
  pivot_longer(starts_with("scr_rc_"), names_to = "range_cor", values_to = "scr") %>% 
  mutate(transformation = transformation %>% gsub("scr_", "", .) %>% as_factor(),
         range_cor = range_cor %>% gsub("scr_rc_", "", .) %>% as_factor())

#data_long %>% filter(scr %>% is.nan())
```

```{r cs discrimination}
### Add CS discrimination
data_long = data_long %>% filter(stimulus != "ucs") %>% 
  pivot_wider(names_from = stimulus, values_from = "scr") %>% 
  mutate(csd = csp - csm, #"trial"-level cs-difference only works because same amount of cs+ and cs- trials (and trials are counted with cs category)
         stimulus = "csd") %>% rename(scr = csd) %>% #a bit hacky preparation for bind_rows
  select(-csp, -csm) %>% bind_rows(data_long, .)
```

```{r boxcox & csd}
#TODO does it make sense for boxcox to transform first and then calculate difference? Probably not due to different non-linear transformations = non-comparable scales => do boxcox again for raw csd (separate for range_cor, which is a linear transformation)
data_long = data_long %>% filter(transformation=="raw", stimulus=="csd") %>% 
  group_by(range_cor) %>% mutate(scr = boxcoxvec(scr)) %>% ungroup() %>% 
  mutate(transformation="box") %>% 
  bind_rows(data_long %>% filter(transformation!="box" | stimulus!="csd"), .) #%>% full_join(data_long, by = c("id", "trialnr", "stimulus", "stim_cat", "transformation", "range_cor")) %>% filter(scr.x != scr.y) %>% select(stimulus, stim_cat, transformation, range_cor) %>% unique()
```

``` {r export trial-level data}
data_long %>% write_rds("Merz_transformations.rds" %>% paste0("data/", .))
```

#### Reliability

```{r reliability}
#checks
data_long %>% summarise(trials = max(trialnr), .by = stimulus)
#data_long %>% group_by(stimulus, id) %>% summarise(trials = n()) %>% summarise(trials = mean(trials))

#reliability cs difference
data_wide_csd = data_long %>% filter(stimulus=="csd") %>% 
  mutate(condition = paste(transformation, range_cor, sep="_"),
                                 condition = condition %>% gsub("_none", "", .) %>% gsub("_", "_rc_", .)) %>% 
  pivot_wider(names_from=condition, values_from=scr, id_cols=c(id, trialnr, stimulus))

replications = 1000
set.seed(6723094)
reliabilities.permutations = tibble(
  raw = reliability_helper(data_wide_csd, fn_score_mean("raw"), replications),
  log = reliability_helper(data_wide_csd, fn_score_mean("log"), replications),
  sqr = reliability_helper(data_wide_csd, fn_score_mean("sqr"), replications),
  box = reliability_helper(data_wide_csd, fn_score_mean("box"), replications),
  ztr = reliability_helper(data_wide_csd, fn_score_mean("ztr"), replications),
  
  raw_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("raw_rc_cs"), replications),
  log_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("log_rc_cs"), replications),
  sqr_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("sqr_rc_cs"), replications),
  box_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("box_rc_cs"), replications),
  ztr_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("ztr_rc_cs"), replications),
  
  raw_rc_us = reliability_helper(data_wide_csd, fn_score_mean("raw_rc_us"), replications),
  log_rc_us = reliability_helper(data_wide_csd, fn_score_mean("log_rc_us"), replications),
  sqr_rc_us = reliability_helper(data_wide_csd, fn_score_mean("sqr_rc_us"), replications),
  box_rc_us = reliability_helper(data_wide_csd, fn_score_mean("box_rc_us"), replications),
  ztr_rc_us = reliability_helper(data_wide_csd, fn_score_mean("ztr_rc_us"), replications)
)
reliabilities = reliabilities.permutations %>% 
  summarise(across(.fns=list(m = fnFishZ, sd = ~ fnFishZ(.x, fn=sd),
                             CI95.lo = ~ fnFishZ(.x, fn=quantile, probs=.025),
                             CI95.hi = ~ fnFishZ(.x, fn=quantile, probs=.975)), 
            .cols=everything(), .names="{.col}_x_{.fn}")) %>% 
  pivot_longer(cols=everything()) %>% separate(col=name, into=c("method", "metric"), sep="_x_") %>% 
  pivot_wider(names_from = "metric", id_cols = "method") %>% arrange(desc(m)) %>% 
  separate(method, into=c("transformation", "range_cor"), sep="_rc_", fill="right", remove=F) %>% 
  mutate(range_cor = range_cor %>% replace_na("none")) %>% 
  group_by(transformation) %>% mutate(rank_rc = rank(-m)) %>% ungroup() %>% 
  group_by(range_cor) %>% mutate(rank_trans = rank(-m)) %>% ungroup()

reliabilities #overall descending

reliabilities %>% summarise(mean_rank = rank_rc %>% mean(), .by=range_cor)
#reliabilities %>% arrange(transformation, rank_rc)

reliabilities %>% summarise(mean_rank = rank_trans %>% mean(), .by=transformation) %>% arrange(mean_rank)
reliabilities %>% filter(range_cor=="none") %>% arrange(rank_trans)
```

``` {r effect size}
effects = data_long %>% filter(stimulus=="csd") %>% 
  group_by(transformation, range_cor, id) %>% summarise(scr = mean(scr)) %>% #subject-level aggregates for correct between SD calculation
  summarise(effect = mean(scr)/sd(scr), #checked against apa::cohens_d(scr) #TODO use Hedge's g instead
            helper = apa::t_test(scr) %>% apa::t_apa(es_ci=T, print=F) %>% gsub("\\[", ";", .) %>% gsub("\\]", "", .)) %>% 
  separate_wider_delim(helper, delim=";", names=c(NA, "CI95.lo", "CI95.hi")) %>% mutate(across(contains("CI"), as.numeric)) %>%
  group_by(transformation) %>% mutate(rank_rc = rank(-effect)) %>% ungroup() %>% 
  group_by(range_cor) %>% mutate(rank_trans = rank(-effect)) %>% ungroup() %>% 
  arrange(desc(effect))

effects

effects %>% summarise(mean_rank = rank_trans %>% mean(), .by=transformation) %>% arrange(mean_rank)
effects %>% summarise(mean_rank = rank_rc %>% mean(), .by=range_cor) %>% arrange(mean_rank)
```

``` {r export data multiverse}
data_multiverse = effects %>% select(-contains("rank")) %>% rename_with(function(x) paste0("effect_", x), .cols=contains("CI")) %>% 
  full_join(reliabilities %>% rename(rel = m) %>% select(transformation, range_cor, rel, contains("CI")) %>% rename_with(function(x) paste0("rel_", x), .cols=contains("CI")))
data_multiverse %>% write_rds("Merz_multiverse.rds" %>% paste0("data/", .))
```

``` {r old: reliability across stimuli (stratified), eval=F}
data_wide = data_long %>% mutate(condition = paste(transformation, range_cor, sep="_"),
                                 condition = condition %>% gsub("_none", "", .) %>% gsub("_", "_rc_", .)) %>% 
  pivot_wider(names_from=condition, values_from=scr, id_cols=c(id, trialnr, stimulus))
reliabilities.strat.permutations = tibble(
  raw = reliability_helper(data_wide, fn_score_mean("raw"), replications, stratification="stimulus"),
  log = reliability_helper(data_wide, fn_score_mean("log"), replications, stratification="stimulus"),
  sqr = reliability_helper(data_wide, fn_score_mean("sqr"), replications, stratification="stimulus"),
  box = reliability_helper(data_wide, fn_score_mean("box"), replications, stratification="stimulus"),
  ztr = reliability_helper(data_wide, fn_score_mean("ztr"), replications, stratification="stimulus"),
  
  raw_rc_cs = reliability_helper(data_wide, fn_score_mean("raw_rc_cs"), replications, stratification="stimulus"),
  log_rc_cs = reliability_helper(data_wide, fn_score_mean("log_rc_cs"), replications, stratification="stimulus"),
  sqr_rc_cs = reliability_helper(data_wide, fn_score_mean("sqr_rc_cs"), replications, stratification="stimulus"),
  box_rc_cs = reliability_helper(data_wide, fn_score_mean("box_rc_cs"), replications, stratification="stimulus"),
  ztr_rc_cs = reliability_helper(data_wide, fn_score_mean("ztr_rc_cs"), replications, stratification="stimulus"),
  
  raw_rc_us = reliability_helper(data_wide, fn_score_mean("raw_rc_us"), replications, stratification="stimulus"),
  log_rc_us = reliability_helper(data_wide, fn_score_mean("log_rc_us"), replications, stratification="stimulus"),
  sqr_rc_us = reliability_helper(data_wide, fn_score_mean("sqr_rc_us"), replications, stratification="stimulus"),
  box_rc_us = reliability_helper(data_wide, fn_score_mean("box_rc_us"), replications, stratification="stimulus"),
  ztr_rc_us = reliability_helper(data_wide, fn_score_mean("ztr_rc_us"), replications, stratification="stimulus")
)
reliabilities.strat = reliabilities.strat.permutations %>% 
  summarise(across(.fns=list(m = fnFishZ, sd = ~ fnFishZ(.x, fn=sd)), 
            .cols=everything(), .names="{.col}_x_{.fn}")) %>% 
  pivot_longer(cols=everything()) %>% separate(col=name, into=c("method", "metric"), sep="_x_") %>% 
  pivot_wider(names_from = "metric", id_cols = "method") %>% arrange(desc(m))
reliabilities.strat
```



```{r prep-B07-data-set}

# Load data (only ACQ and T0)?
load("./data/dataSCR_B07.RData")
data_B07 <- dataSCR


# Exclude some participants: as Rachel: 10, 81
# and 17 because has one missing trial
id_excl <- c(10, 17, 81)
data_B07 <- data_B07[!is.element(data_B07$id, id_excl), ]

######################## Exclusion due to non-responding? Still has to be decided
# # Who has zero responses only? -> range correction does not work!
# id_zero_cs <- unique(data_B07$id[which(data_B07$scr_max_cs == 0)])
# id_zero_us <- unique(data_B07$id[which(data_B07$scr_max_us == 0)])
# 
# # Exclude these participants: 30, 33, 60, 91
# id_excl_zero <- c(30, 33, 60, 91)
# data_B07 <- data_B07[!is.element(data_B07$id, id_excl_zero), ]


###################################################################################

# Rename some variables
names(data_B07)[grep("trial", names(data_B07))] <- "trialnr"
names(data_B07)[grep("stim_type", names(data_B07))] <- "stimulus"
names(data_B07)[grep("trial", names(data_B07))] <- "trialnr"
data_B07$stimulus <- gsub("CS_P","csp", data_B07$stimulus)
data_B07$stimulus <- gsub("CS_M","csm", data_B07$stimulus)
data_B07$stimulus <- gsub("US","ucs", data_B07$stimulus)

# Add variable: category of stimulus
data_B07$stim_cat <- NA
data_B07$stim_cat[grep("cs", data_B07$stimulus)] <- "cs"
data_B07$stim_cat[grep("ucs", data_B07$stimulus)] <- "ucs"

# Reorder the data frame
data_B07 <- data_B07[ ,c("id","trialnr","stimulus","stim_cat","scr_raw")]


### Transformations
# Log-transform the raw data
data_B07 = data_B07 %>% 
  mutate(scr_log = log10(1+scr_raw),
         scr_sqr = sqrt(scr_raw)) %>% 
  
  # group_by(stimulus) %>% mutate(scr_shift = scr_raw - min(scr_raw) + 1, 
  #                               lambda = boxcox(scr_shift ~ 1, plotit=F) %>% 
  #                                 bind_cols() %>% filter(y == max(y)) %>% pull(x) %>% mean()) %>% ungroup() %>% 
  # mutate(scr_box_check = (scr_shift ^ lambda - 1) / lambda) %>% 
  group_by(stimulus) %>% mutate(scr_box = boxcoxvec(scr_raw)) %>% ungroup() %>% 
  
  #group_by(id) %>% #this implicitly invokes something similar to a range correction => don't do it? How is it used in the literature?
  mutate(scr_ztr = scale(scr_raw)[,1],
         scr_ztr = scr_ztr - min(scr_ztr)) #make sure that minimum response is 0 (and not negative)

#View(data_B07)
#data_B07 %>% ggplot(aes(x = scr_raw, y = scr_box, color = stimulus)) + geom_point() + theme_bw()
#data_B07 %>% filter(transformation %>% grepl("box", .)) %>% pivot_wider(names_from=transformation, values_from=scr) %>% filter(scr_box != scr_box_check)

data_B07 = data_B07 %>% 
  #select(-scr_shift, -lambda) %>% #remove helping variables
  pivot_longer(starts_with("scr_"), names_to = "transformation", values_to = "scr")


### range correction
# Prepare range correction by calculating max SCR of CS and US responses
data_B07.max = data_B07 %>% 
  summarise(scr_max = max(scr, na.rm=T), .by = c(id, stim_cat, transformation)) %>% 
  pivot_wider(names_from = stim_cat, names_prefix = "max_", values_from = scr_max, id_cols = c("id", "transformation"))

data_B07.max %>% summarise(across(starts_with("max"), list("min" = min, "max" = max)))
#some participant's max response is negative (probably due to z-transform across all participants, i.e., their max is still below the group average)
# => absolute value of minimum has been "added" to shift z-scored values to a minimum of 0

data_B07.max %>% filter(max_cs == 0 | max_ucs == 0)
# no subject showed only zero responses to CSs

data_B07.max = data_B07.max %>% mutate(across(starts_with("max_"), function(x) {if_else(x == 0, Inf, x)})) #replace 0 with Inf (such that scr / Inf == 0)

data_B07 = data_B07 %>% full_join(data_B07.max) %>% 
  mutate(scr_rc_cs = scr / max_cs,
         scr_rc_us = scr / max_ucs) %>% 
         #stimulus = if_else(stimulus %>% is.na(), "ucs", stimulus) %>% as_factor()) %>% 
  dplyr::select(-starts_with("max_")) %>% rename(scr_rc_none = scr) %>% 
  pivot_longer(starts_with("scr_rc_"), names_to = "range_cor", values_to = "scr") %>% 
  mutate(transformation = transformation %>% gsub("scr_", "", .) %>% as_factor(),
         range_cor = range_cor %>% gsub("scr_rc_", "", .) %>% as_factor())

#data_B07 %>% filter(scr %>% is.nan())


### CS discrimination
### Add CS discrimination
data_B07 = data_B07 %>% filter(stimulus != "ucs") %>% 
  pivot_wider(names_from = stimulus, values_from = "scr") %>% 
  mutate(csd = csp - csm, #"trial"-level cs-difference only works because same amount of cs+ and cs- trials (and trials are counted with cs category)
         stimulus = "csd") %>% rename(scr = csd) %>% #a bit hacky preparation for bind_rows
  dplyr::select(-csp, -csm) %>% bind_rows(data_B07, .)


### Boxcox & csd
#TODO does it make sense for boxcox to transform first and then calculate difference? Probably not due to different non-linear transformations = non-comparable scales => do boxcox again for raw csd (separate for range_cor, which is a linear transformation)
data_B07 = data_B07 %>% filter(transformation=="raw", stimulus=="csd") %>% 
  group_by(range_cor) %>% mutate(scr = boxcoxvec(scr)) %>% ungroup() %>% 
  mutate(transformation="box") %>% 
  bind_rows(data_B07 %>% filter(transformation!="box" | stimulus!="csd"), .) #%>% full_join(data_B07, by = c("id", "trialnr", "stimulus", "stim_cat", "transformation", "range_cor")) %>% filter(scr.x != scr.y) %>% select(stimulus, stim_cat, transformation, range_cor) %>% unique()


### Reliability
#checks
data_B07 %>% summarise(trials = max(trialnr), .by = stimulus)
#data_B07 %>% group_by(stimulus, id) %>% summarise(trials = n()) %>% summarise(trials = mean(trials))

#reliability cs difference
data_wide_csd = data_B07 %>% filter(stimulus=="csd") %>% 
  mutate(condition = paste(transformation, range_cor, sep="_"),
                                 condition = condition %>% gsub("_none", "", .) %>% gsub("_", "_rc_", .)) %>% 
  pivot_wider(names_from=condition, values_from=scr, id_cols=c(id, trialnr, stimulus))

replications = 1000
set.seed(6723094)
reliabilities.permutations = tibble(
  raw = reliability_helper(data_wide_csd, fn_score_mean("raw"), replications),
  log = reliability_helper(data_wide_csd, fn_score_mean("log"), replications),
  sqr = reliability_helper(data_wide_csd, fn_score_mean("sqr"), replications),
  box = reliability_helper(data_wide_csd, fn_score_mean("box"), replications),
  ztr = reliability_helper(data_wide_csd, fn_score_mean("ztr"), replications),
  
  raw_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("raw_rc_cs"), replications),
  log_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("log_rc_cs"), replications),
  sqr_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("sqr_rc_cs"), replications),
  box_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("box_rc_cs"), replications),
  ztr_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("ztr_rc_cs"), replications),
  
  raw_rc_us = reliability_helper(data_wide_csd, fn_score_mean("raw_rc_us"), replications),
  log_rc_us = reliability_helper(data_wide_csd, fn_score_mean("log_rc_us"), replications),
  sqr_rc_us = reliability_helper(data_wide_csd, fn_score_mean("sqr_rc_us"), replications),
  box_rc_us = reliability_helper(data_wide_csd, fn_score_mean("box_rc_us"), replications),
  ztr_rc_us = reliability_helper(data_wide_csd, fn_score_mean("ztr_rc_us"), replications)
)
reliabilities = reliabilities.permutations %>% 
  summarise(across(.fns=list(m = fnFishZ, sd = ~ fnFishZ(.x, fn=sd),
                             CI95.lo = ~ fnFishZ(.x, fn=quantile, probs=.025),
                             CI95.hi = ~ fnFishZ(.x, fn=quantile, probs=.975)), 
            .cols=everything(), .names="{.col}_x_{.fn}")) %>% 
  pivot_longer(cols=everything()) %>% separate(col=name, into=c("method", "metric"), sep="_x_") %>% 
  pivot_wider(names_from = "metric", id_cols = "method") %>% arrange(desc(m)) %>% 
  separate(method, into=c("transformation", "range_cor"), sep="_rc_", fill="right", remove=F) %>% 
  mutate(range_cor = range_cor %>% replace_na("none")) %>% 
  group_by(transformation) %>% mutate(rank_rc = rank(-m)) %>% ungroup() %>% 
  group_by(range_cor) %>% mutate(rank_trans = rank(-m)) %>% ungroup()

reliabilities #overall descending

reliabilities %>% summarise(mean_rank = rank_rc %>% mean(), .by=range_cor)
#reliabilities %>% arrange(transformation, rank_rc)

reliabilities %>% summarise(mean_rank = rank_trans %>% mean(), .by=transformation) %>% arrange(mean_rank)
reliabilities %>% filter(range_cor=="none") %>% arrange(rank_trans)


### Effect size
effects = data_B07 %>% filter(stimulus=="csd") %>% 
  group_by(transformation, range_cor, id) %>% summarise(scr = mean(scr)) %>% #subject-level aggregates for correct between SD calculation
  summarise(effect = mean(scr)/sd(scr), #checked against apa::cohens_d(scr) #TODO use Hedge's g instead
            helper = apa::t_test(scr) %>% apa::t_apa(es_ci=T, print=F) %>% gsub("\\[", ";", .) %>% gsub("\\]", "", .)) %>% 
  separate_wider_delim(helper, delim=";", names=c(NA, "CI95.lo", "CI95.hi")) %>% mutate(across(contains("CI"), as.numeric)) %>%
  group_by(transformation) %>% mutate(rank_rc = rank(-effect)) %>% ungroup() %>% 
  group_by(range_cor) %>% mutate(rank_trans = rank(-effect)) %>% ungroup() %>% 
  arrange(desc(effect))

effects

effects %>% summarise(mean_rank = rank_trans %>% mean(), .by=transformation) %>% arrange(mean_rank)
effects %>% summarise(mean_rank = rank_rc %>% mean(), .by=range_cor) %>% arrange(mean_rank)


### Create data set for the specification curve
data_multiverse_B07 = effects %>% dplyr::select(-contains("rank")) %>% rename_with(function(x) paste0("effect_", x), .cols=contains("CI")) %>% 
  full_join(reliabilities %>% rename(rel = m) %>% dplyr::select(transformation, range_cor, rel, contains("CI")) %>% rename_with(function(x) paste0("rel_", x), .cols=contains("CI")))
data_multiverse_B07 %>% write_rds("B07_multiverse.rds" %>% paste0("data/", .))



```



#### Krippendorf's alpha

```{r krippendorfs}
# use the function by Zapf to also extract confidence intervals, using bootstrapping
source('./scripts/Zapf_Krip_alpha_function.R')

# set number of bootstrapping, should be 1000, but reduce for testing code
n_boots <- 10
save_fig = 'yes'
x_lab <- expression(paste('Krippendorff\'s ',alpha))
y_lab <- 'all together'
```

```{r kripp-prep}
# loop through dataframes that only contain one trial (ie.unique cs type and number)

# remove TTP approach (i.e, 10) from dat: approach %in% 1:9
# remove approach 9 (i.e, SCL) for visualisation: approach %in% 1:8 for suppl
dat <- data_long [c(1,3:8)]
dat2 <- dat %>%
  pivot_longer(cols = -c(id, trialnr, stimulus), 
               names_to = "approach", 
               values_to = "scr") 
  
  
# split into different dataframes
# 42 acquistition trials

dat_split_per_trial <- dat2 %>%
  dplyr::select(id, approach, stimulus, trialnr, scr) %>% # changed this to scr instead of scr_log_r
  group_split(stimulus,trialnr)

# build dataframe for extracted data
ka_df <- data.frame(trial = NA,
                    kaZ_rank = NA, 
                    kaZ_rank_lc = NA,
                    kaZ_rank_uc = NA)

# loop through 48 trials (118 subjects * 9 methods = 1380 observations per df)
for (ind in 1:48){
  df <- dat_split_per_trial[[ind]] # trial 1, csm
  
  # dataframe for kripp alpha function from Zapf et al 2016
  df_2 <- df %>% pivot_wider(names_from = approach, 
                             values_from = scr, 
                             names_prefix = 'approach') %>% # changed this to scr instead of scr_log_r
    dplyr::select(-c(id,stimulus,trialnr)) %>%
    as.matrix()
  
  # compute, note nboot is 10 statt 1000, sonst dauert das ewig!
  k_zapf_rank <- k_alpha(df_2, scaling = 'ordinal', nboot = n_boots)
  
  # print(paste(df$cs[1], df$number_cs[1], sep = '_'))
  ka_df[ind,'cs'  ] <-  df$stimulus[1]
  ka_df[ind,'trial'  ] <-  paste(df$stimulus[1], df$trialnr[1], sep = '_')
  ka_df[ind, 'kaZ_rank'] <- k_zapf_rank$est.alpha
  ka_df[ind, 'kaZ_rank_lc'] <- k_zapf_rank$ci.boot.alpha[1]
  ka_df[ind, 'kaZ_rank_uc'] <- k_zapf_rank$ci.boot.alpha[2]
  
}
#print values , does the fucntion kable() work here?           
knitr::kable(ka_df) 
```

```{r update-str-df-ka-avg}
# update structure of ka_df
ka_df$trial <- factor(ka_df$trial, levels = ka_df$trial)
ka_df$stimType <- sub('_([^_]*)$','', ka_df$trial)
```


```{r build-plot-ka-avg}
# plot
p_kA <- ggplot(ka_df, aes(x = kaZ_rank, y = trial, color = stimType)) +
  geom_point(aes(x = kaZ_rank),size = 5) +
  geom_errorbarh(aes(xmin = kaZ_rank_lc, xmax = kaZ_rank_uc), height = 0, size = 1.5) +
  #scale_color_manual(name = NULL, values = c('blue','red','black'), labels = c('CS -', 'CS +', 'US'), guide = guide_legend(reverse=TRUE)) +
  xlim(0,1) +
  xlab(x_lab) +
  ylab(y_lab) +
  scale_y_discrete(labels = c('CS_M_1' = '1', 'CS_M_14' = '14',
                              'CS_P_1' = '1', 'CS_P_14' = '14',
                              'US_1' = '1', 'US_14' = '14'), 
                   breaks = c('CS_M_1', 'CS_M_14', 'CS_P_1', 'CS_P_14',
                              'US_1', 'US_14')) +
  # add benchmarks
  geom_vline(xintercept = c(.4, .6, .8), linetype = 'longdash') +
  # add label for benchmarks
  annotate('text', x = .45, y = 42, label = 'fair') +
  annotate('text', x = .65, y = 42, label = 'moderate') +
  annotate('text', x = .85, y = 42, label = 'perfect') +
  theme_classic() +
  theme(text = element_text(size=28), 
        legend.position = "right" ) #c(.90, .25)
p_kA
```

#### Pairwise (i.e, approach wise) comparisons of Krippendorff's alpha

```{r estimate-ka-pairwise}
# loop through dataframes that only contain one trial (ie.unique cs type and number)

# split into different dataframes
# 42 acquistition trials
dat_split_per_trial <- dat2 %>%
  dplyr::select(id, approach, stimulus, trialnr, scr) %>%
  group_split(stimulus,trialnr)

# build dataframe for extracted data
ka_df <- data.frame(trial = NA,
                    stimType= NA,
                    kaZ_rank = NA, 
                    kaZ_rank_lc = NA,
                    kaZ_rank_uc = NA,
                    app_x = NA,
                    app_y = NA)
ka_df_pw <- ka_df

# loop through 42 trials (118 subjects * 10 methods = 1180 observations per df, if no NAs in TTP)
for (ind in 1:48){
  df <- dat_split_per_trial[[ind]] # trial 1, csm
  df$approach = as.factor(df$approach)
  # select combinations
  for(app_x in 1:(nlevels(df$approach)-1)){
    for(app_y in (app_x+1):nlevels(df$approach)){
      
      # select 2 approaches to compare, for every subject there are 2 values for the 2 approaches specific stimulus type at this trial, i.e., ideally 118 * 2 values
      df_xy <- df %>%
        filter(approach %in% c(app_x, app_y)) %>%
        droplevels()
      
      
      # dataframe for kripp alpha function from Zapf et al 2016
      df_2 <- df %>% pivot_wider(names_from = approach, 
                                    values_from = scr, 
                                    names_prefix = 'approach') %>%
        dplyr::select(-c(id,stimulus,trialnr)) %>%
        as.matrix()
      
      # compute, adjust nboot to save time
      # note for all 45 approach comparisons, I set nboot = 1 which does not make sense   for calc a confidence interval off course, bc only 1 value is estimated
      # for 45 (unique approach combinations) and 42 trial = 1890 estimations, this took approx 20 mins to run
      k_zapf_rank <- k_alpha(df_2, scaling = 'ordinal', nboot = n_boots)
      
      # 
      # print(paste(df$cs[1], df$number_cs[1], sep = '_'))
      
      ka_df$trial <-  paste(df$stimulus[1], df$trialnr[1], sep = '_')
      ka_df$stimType <- as.character(df$stimulus[1])
      ka_df$kaZ_rank <- k_zapf_rank$est.alpha
      ka_df$kaZ_rank_lc <- k_zapf_rank$ci.boot.alpha[1]
      ka_df$kaZ_rank_uc <- k_zapf_rank$ci.boot.alpha[2]
      ka_df$app_x <- app_x
      ka_df$app_y <- app_y
      
      # put in one large dataframe
      ka_df_pw <- rbind(ka_df_pw, ka_df)
      
    }
  }
}
#print values , does the fucntion kable() work here?           
#kable(ka_df) 

Sys.time()
```

```{r update-str-df}
ka_df_pw <- ka_df_pw[-1, ]  # first row were NAs
ka_df_pw$stimType <- as.factor(ka_df_pw$stimType)
ka_df_pw$trial <- factor(ka_df_pw$trial, levels = unique(ka_df_pw$trial))
ka_df_pw$trial_nr <- factor(gsub('^.*_','',ka_df_pw$trial), levels = 1:14)
#ka_df_pw$app_x <- factor(ka_df_pw$app_x, levels = unique(ka_df_pw$app_x))
#ka_df_pw$app_y <- factor(ka_df_pw$app_y, levels = unique(ka_df_pw$app_y))
```

Now plot Kripp alpha for always two approaches separately for all stimulus types.

```{r settings-plot}
lim_x <- c(-1,1)  # most accurate
lim_x <- c(-.3,1)  # for better data visualisation
```

```{r build-plot-ka-pairwise}
# rename approach 10 to TTP, to avoid confusion
ka_df_pw[ka_df_pw$app_x == 1, 'app_x'] <- 'box'
ka_df_pw[ka_df_pw$app_x == 2, 'app_x'] <- 'log'
ka_df_pw[ka_df_pw$app_x == 3, 'app_x'] <- 'raw'
ka_df_pw[ka_df_pw$app_x == 4, 'app_x'] <- 'sqrt'

ka_df_pw[ka_df_pw$app_y == 1, 'app_y'] <- 'box'
ka_df_pw[ka_df_pw$app_y == 2, 'app_y'] <- 'log'
ka_df_pw[ka_df_pw$app_y == 3, 'app_y'] <- 'raw'
ka_df_pw[ka_df_pw$app_y == 4, 'app_y'] <- 'sqrt'

# start with splitting the df per comparison
ka_per_comp <- ka_df_pw %>% 
  group_split(app_x, app_y) 

# 45 comparisons: 9 BLC approaches, 1 TTP method
for (ind in 1:6){
 df_temp <- ka_per_comp[[ind]] %>%
   data.frame()

 plot_ind <- df_temp %>%
   ggplot(aes(x = kaZ_rank, y = trial, color = stimType)) +
   geom_point(aes(x = kaZ_rank)) +
   geom_errorbarh(aes(xmin = kaZ_rank_lc, xmax = kaZ_rank_uc), height = 0.5) +
   #scale_color_manual(values = c('blue','red','black')) +
   scale_y_discrete(labels = c('CS_M_1' = '1','CS_M_14' = '14',
                              'CS_P_1' = '1','CS_P_14' = '14',
                              'US_1' = '1','US_14' = '14'), 
                   breaks = c('CS_M_1','CS_M_14','CS_P_1','CS_P_14',
                              'US_1','US_14')) +
    # add benchmarks
  geom_vline(xintercept = c(.4, .6, .8), linetype = 'longdash') +
   scale_x_continuous(n.breaks = 3, limits = lim_x) +
   ggtitle(paste0(df_temp$app_x[1], ' vs ', df_temp$app_y[1])) +
   xlab(x_lab) +
   theme_classic() +
   theme(legend.position = "none",
         text = element_text(size=16) ) +
   theme(axis.title = element_blank())
 plot_ind
   # temporary without legend for matrix arrangement

assign(paste('plot_ind',ind, sep = '_'), plot_ind)
}

# combine plots using a matrix
plot_mat <- matrix(nrow = 3, ncol = 3, byrow = T)
plot_ind <- upper.tri(plot_mat, diag = T)

plot_mat[plot_ind] <- c(1,2,3,4,5,6)
#paste0('plot_ind_',1:45,collapse = ',')
plot_list <- list(plot_ind_1,plot_ind_2,plot_ind_3,plot_ind_4,plot_ind_5,plot_ind_6)

# fill matrix with plots
plot_upp_tri <- gridExtra::grid.arrange(grobs = plot_list, layout_matrix = plot_mat) 
```

```{r save-plot-ka-pairwise}
# save plot
if (save_fig == 'yes'){
png(paste0('figures/fig_', '_krippalph_tranf.png'), units="in", width=24, height=24, res=300)
plot(plot_upp_tri)
dev.off()
}
```

```{r arrange-ka-plots}
# arrangement with patchwork

# make list of all plots to be plotted
 plot_list_2 <- c(plot_list, list(p_kA))

 # build index of letters for layout of design "matrix"
 letter_ind <- c(rbind(letters[1:3], LETTERS[1:3]))


# plot and add labels
plot_combined <-  wrap_plots(plot_list_2) +
  plot_layout(tag_level = 'new') 
  #plot_annotation(tag_levels = list(c('B', rep('', 4), 'A')))
plot_combined
```
