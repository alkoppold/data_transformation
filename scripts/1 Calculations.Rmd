---
title: "1_Calculations"
author: "Alina Koppold"
date: "2023-11-08"
params:
  # data: "1" #"Merz"
  # data: "2" #"Klingelh"
  # data: "3" #"Reutter_hr"
  data: "4" #"Reutter_pupil"
  # data: "5" #"Klingelh_FPS",
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(haven)
#library(MASS) #don't load MASS to not override dplyr::select
library(splithalfr)
#library(effsize)
#library(esci)
library(tidyverse)
rm(list = ls() %>% setdiff("params"))
```

```{r helpers}
boxcoxvec = function(x, min=1) { #cf. scales::boxcox_trans()
  if (min %>% is.numeric()) x = x - min(x, na.rm=T) + min
  x.noNA = x %>% discard(is.na)
  lambda = MASS::boxcox(x.noNA ~ 1, plotit=F) %>% 
    bind_cols() %>% filter(y == max(y)) %>% pull(x) %>% mean()
  return((x ^ lambda - 1) / lambda)
}

prune = function(x, low=-Inf, high=+Inf, abs=NA) {
  result = if_else(x < low, low, x) %>% if_else(. > high, high, .)
  if (abs %>% is.na() == F) result = if_else(abs(result) > abs, abs * if_else(result > 0, 1, -1), result)
  return(result)
}

reliability_helper = function(data, fn_score, replications, #need to be specified
                              participants="id", stratification=NULL, #constant for one data set
                              fn_coef=splithalfr::spearman_brown, ncores=parallel::detectCores() - 1, careful=F, verbose=F) #sensible defaults
{
  if (stratification %>% is.null() == F) stratification = data %>% pull(!!stratification)
  splithalfr::by_split(data=data, fn_score=fn_score, replications=replications,
                       participants = data %>% pull(!!participants), 
                       stratification = stratification,
                       ncores=ncores, careful=careful, verbose=verbose) %>% 
    splithalfr::split_coefs(fn_coef=fn_coef)
}

fn_score_mean = function(column, na.rm=T) { #idea: create a function that
  return(function(df) { #returns another function 
    return(mean(pull(df, !!column), na.rm=na.rm)) #with specifications (column & na.rm) from the parent-function => parameter df gets filled inside by_split function call
    #note: this would not be needed if by_split had a "..." argument that gets passed into fn_score
    
    #return(df %>% pull(!!column) %>% mean(na.rm=na.rm)) #requires library(tidyverse) for parallel (inefficient)
  })
}

rToFishZ = function(r) { return(.5*log((1+r)/(1-r))) }
fishZtoR = function(Z) { return(ifelse(Z==Inf, 1, (exp(2*Z)-1)/(exp(2*Z)+1))) }
fnFishZ = function(r, fn=mean, prune=.999, ...) { 
  warning.txt = ""
  if (any(abs(r) >= 1, na.rm=T)) {
    warning.txt = "Correlation(s) contain(s) values at or beyond 1. This will bias results for summary functions." %>% paste0(warning.txt, .)
    if (prune %>% is.na()) warning = "Consider setting prune parameter." %>% paste(warning.txt, .)
    else {
      warning.txt = paste0("Pruning to ", prune, ".") %>% paste(warning.txt, .)
      
      r = r %>% prune(abs=prune) #if_else(abs(r) >= 1, prune * if_else(r > 0, 1, -1), r)
    }
    warning(warning.txt)
  }
  
  return(r %>% rToFishZ() %>% fn(...) %>% fishZtoR()) 
}
```

```{r data}

# Choose the dataset
# data_choice <- readline(prompt = "Enter the number of the dataset you want to use (1 = merz eda, 2 = klingelh eda, 3 = reutter hr, 4 = reutter pupil): ") 
# readline doesn't work with RMarkdown: https://stackoverflow.com/a/45904949/4011953
data_choice = {function() return(params$data)}()
data_of_interest <- switch(data_choice,
                           "1" = "Merz",
                           "2" = "Klingelh",
                           "3" = "Reutter_hr",
                           "4" = "Reutter_pupil",
                           "5" = "Klingelh_FPS",
                            "")

# Load the selected dataset
if (data_of_interest == "Merz") {
  data_long <- haven::read_sav("data/Merz.sav") %>%
    rename(id = Versuchspersonennummer) %>%
    pivot_longer(-id, names_to = "condition", values_to = "scr_raw") %>%
    separate(condition, into = c(NA, NA, NA, "stimulus", "trialnr"), sep = "_") %>%
    mutate(trialnr = trialnr %>% str_extract("\\d+") %>% as.integer()) %>%
    filter(stimulus %in% c("cspe", "csm", "ucs")) %>%
    mutate(stimulus = if_else(stimulus == "cspe", "csp", stimulus),
           stim_cat = if_else(startsWith(stimulus, "cs"), "cs", "ucs")) %>%
    select(id, trialnr, stimulus, stim_cat, scr_raw)
} else if (data_of_interest == "Klingelh") {
  load("./data/dataSCR_B07.RData")
  data_B07 <- dataSCR
  # Exclude some participants: as Rachel: 10, 81
  # and 17 because has one missing trial
  id_excl <- c(10, 17, 81)
  data_B07 <- data_B07[!is.element(data_B07$id, id_excl), ]
  # # Exclude non-responders?: 30, 33, 60, 91
  # id_excl_zero <- c(30, 33, 60, 91)
  # data_B07 <- data_B07[!is.element(data_B07$id, id_excl_zero), ]
  # Rename some variables
  names(data_B07)[grep("trial", names(data_B07))] <- "trialnr"
  names(data_B07)[grep("stim_type", names(data_B07))] <- "stimulus"
  names(data_B07)[grep("trial", names(data_B07))] <- "trialnr"
  data_B07$stimulus <- gsub("CS_P","csp", data_B07$stimulus)
  data_B07$stimulus <- gsub("CS_M","csm", data_B07$stimulus)
  data_B07$stimulus <- gsub("US","ucs", data_B07$stimulus)
  # Add variable: category of stimulus
  data_B07$stim_cat <- NA
  data_B07$stim_cat[grep("cs", data_B07$stimulus)] <- "cs"
  data_B07$stim_cat[grep("ucs", data_B07$stimulus)] <- "ucs"
  # Reorder the data frame
  data_long <- data_B07[ ,c("id","trialnr","stimulus","stim_cat","scr_raw")]
} else if (data_of_interest == "Reutter_hr") {
  data_multiverse <- readRDS("data/heart.rds") %>%
    filter(threat %in% c(1, 6)) %>%
    filter(phase == "Gen") %>%
    mutate(scr_raw = round(60000 / (hrbl + HRchange), digits = 0)) %>%
    select(subject, trial, threat, time, scr_raw) %>%
    rename(stimulus = threat,
           id = subject) %>%
    mutate(stim_cat = "cs",
           stimulus = if_else(stimulus == 6, "csp", "csm"))
  
  data_multiverse$id <- as.numeric(as.character(data_multiverse$id))
  data_multiverse$trial <- as.numeric(as.character(data_multiverse$trial))
  # Order the dataframe based on ID and trialnr
  data_multiverse <- data_multiverse %>% arrange(id, trial)

# Create a new variable trialnr_new using group_by and mutate
data_multiverse <- data_multiverse %>%
  group_by(id, stimulus, trial) %>%
  mutate(trialnr = row_number()) %>%
  ungroup()

  data_long <- data_multiverse %>%
    summarise(.by=c(id, trialnr, stimulus, stim_cat),
              scr_raw = round(mean(scr_raw, na.rm = TRUE), digits = 0))
 } else if (data_of_interest == "Reutter_pupil") {
    data_multiverse <- readRDS("data/Reutter_pupil.trial.avg.rds")%>%
    filter(threat %in% c("CS+", "CS-")) %>%
    filter(phase == "Gen") %>%
    select(subject, trial, threat, mmChange) %>%
    rename(stimulus = threat,
           id = subject) %>%
    mutate(stim_cat = "cs",
           stimulus = if_else(stimulus == "CS+", "csp", "csm"))
  
  data_multiverse$id <- as.numeric(as.character(data_multiverse$id))
  data_multiverse$trial <- as.numeric(as.character(data_multiverse$trial))
  # Order the dataframe based on ID and trialnr
  data_multiverse <- data_multiverse %>% arrange(id, trial)

# Create a new variable trialnr_new using group_by and mutate
data_multiverse <- data_multiverse %>%
  group_by(id, stimulus) %>%
  mutate(trialnr = row_number()) %>%
  ungroup()

  data_long <- data_multiverse %>%
    summarise(.by=c(id, trialnr, stimulus, stim_cat),
              scr_raw = round(mean(mmChange, na.rm = TRUE), digits = 4))
 } else if (data_of_interest == "Klingelh_FPS") {
  load("./data/dataFPS_statAnx.RData")
   names(dataFPS)[grep("FPS",names(dataFPS))] <- "scr_raw"
   data_long <- dataFPS

    
} else {
  stop("Invalid choice.")
}

# Now you have the selected dataset loaded in 'data_long'

```


```{r transformations}
# Log-transform the raw data
data_long = data_long %>% 
  mutate(scr_log = log10(1+scr_raw),
         scr_sqr = sqrt(scr_raw)) %>% 
  
  # group_by(stimulus) %>% mutate(scr_shift = scr_raw - min(scr_raw) + 1, 
  #                               lambda = boxcox(scr_shift ~ 1, plotit=F) %>% 
  #                                 bind_cols() %>% filter(y == max(y)) %>% pull(x) %>% mean()) %>% ungroup() %>% 
  # mutate(scr_box_check = (scr_shift ^ lambda - 1) / lambda) %>% 
  group_by(stimulus) %>% mutate(scr_box = boxcoxvec(scr_raw)) %>% ungroup() %>% 
  
  #group_by(id) %>% #this implicitly invokes something similar to a range correction => don't do it? How is it used in the literature?
  mutate(scr_ztr = scale(scr_raw)[,1],
         scr_ztr = scr_ztr - min(scr_ztr, na.rm = TRUE)) #make sure that minimum response is 0 (and not negative)

#View(data_long)
#data_long %>% ggplot(aes(x = scr_raw, y = scr_box, color = stimulus)) + geom_point() + theme_bw()
#data_long %>% filter(transformation %>% grepl("box", .)) %>% pivot_wider(names_from=transformation, values_from=scr) %>% filter(scr_box != scr_box_check)

data_long = data_long %>% 
  #select(-scr_shift, -lambda) %>% #remove helping variables
  pivot_longer(starts_with("scr_"), names_to = "transformation", values_to = "scr")
```

```{r range correction}
# Prepare range correction by calculating max SCR of CS and US responses
data_long.max = data_long %>% 
  summarise(scr_max = max(scr, na.rm=T), .by = c(id, stim_cat, transformation)) %>% 
  pivot_wider(names_from = stim_cat, names_prefix = "max_", values_from = scr_max, id_cols = c("id", "transformation"))

data_long.max %>% summarise(across(starts_with("max"), list("min" = min, "max" = max)))
#some participant's max response is negative (probably due to z-transform across all participants, i.e., their max is still below the group average)
# => absolute value of minimum has been "added" to shift z-scored values to a minimum of 0

data_long.max %>% filter(max_cs == 0 | max_ucs == 0)
#subject 446: only zero responses to CSs

data_long.max = data_long.max %>% mutate(across(starts_with("max_"), function(x) {if_else(x == 0, Inf, x)})) #replace 0 with Inf (such that scr / Inf == 0)

data_long = data_long %>% full_join(data_long.max) %>% 
  mutate(scr_rc_cs = scr / max_cs,
         scr_rc_us = if ("max_ucs" %in% names(.)) scr / max_ucs else NA) %>% # new by alina, for hr
         #stimulus = if_else(stimulus %>% is.na(), "ucs", stimulus) %>% as_factor()) %>% 
  select(-starts_with("max_")) %>% rename(scr_rc_none = scr) %>% 
  pivot_longer(starts_with("scr_rc_"), names_to = "range_cor", values_to = "scr") %>% 
  mutate(transformation = transformation %>% gsub("scr_", "", .) %>% as_factor(),
         range_cor = range_cor %>% gsub("scr_rc_", "", .) %>% as_factor())

#data_long %>% filter(scr %>% is.nan())
```

```{r cs discrimination}
### Add CS discrimination
data_long = data_long %>% filter(stimulus != "ucs") %>% 
  pivot_wider(names_from = stimulus, values_from = "scr") %>% 
  mutate(csd = csp - csm, #"trial"-level cs-difference only works because same amount of cs+ and cs- trials (and trials are counted with cs category)
         stimulus = "csd") %>% rename(scr = csd) %>% #a bit hacky preparation for bind_rows
  select(-csp, -csm) %>% bind_rows(data_long, .)
```

```{r boxcox & csd}
#TODO does it make sense for boxcox to transform first and then calculate difference? Probably not due to different non-linear transformations = non-comparable scales => do boxcox again for raw csd (separate for range_cor, which is a linear transformation)
data_long = data_long %>% filter(transformation=="raw", stimulus=="csd") %>% 
  group_by(range_cor) %>% mutate(scr = boxcoxvec(scr)) %>% ungroup() %>% 
  mutate(transformation="box") %>% 
  bind_rows(data_long %>% filter(transformation!="box" | stimulus!="csd"), .) #%>% full_join(data_long, by = c("id", "trialnr", "stimulus", "stim_cat", "transformation", "range_cor")) %>% filter(scr.x != scr.y) %>% select(stimulus, stim_cat, transformation, range_cor) %>% unique()
```

``` {r export trial-level data}
data_long %>% write_rds(paste0(data_of_interest, "_transformations.rds") %>% paste0("data/", .))
```

#### Main Calculations for Multiverse

```{r reliability}
#checks
data_long %>% summarise(trials = max(trialnr), .by = stimulus)
#data_long %>% group_by(stimulus, id) %>% summarise(trials = n()) %>% summarise(trials = mean(trials))

#reliability cs difference
data_wide_csd = data_long %>% filter(stimulus=="csd") %>% 
  mutate(condition = paste(transformation, range_cor, sep="_"),
                                 condition = condition %>% gsub("_none", "", .) %>% gsub("_", "_rc_", .)) %>% 
  pivot_wider(names_from=condition, values_from=scr, id_cols=c(id, trialnr, stimulus))

replications = 1000
set.seed(6723094)
reliabilities.permutations = tibble(
  raw = reliability_helper(data_wide_csd, fn_score_mean("raw"), replications),
  log = reliability_helper(data_wide_csd, fn_score_mean("log"), replications),
  sqr = reliability_helper(data_wide_csd, fn_score_mean("sqr"), replications),
  box = reliability_helper(data_wide_csd, fn_score_mean("box"), replications),
  ztr = reliability_helper(data_wide_csd, fn_score_mean("ztr"), replications),
  
  raw_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("raw_rc_cs"), replications),
  log_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("log_rc_cs"), replications),
  sqr_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("sqr_rc_cs"), replications),
  box_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("box_rc_cs"), replications),
  ztr_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("ztr_rc_cs"), replications),
  
  raw_rc_us = reliability_helper(data_wide_csd, fn_score_mean("raw_rc_us"), replications),
  log_rc_us = reliability_helper(data_wide_csd, fn_score_mean("log_rc_us"), replications),
  sqr_rc_us = reliability_helper(data_wide_csd, fn_score_mean("sqr_rc_us"), replications),
  box_rc_us = reliability_helper(data_wide_csd, fn_score_mean("box_rc_us"), replications),
  ztr_rc_us = reliability_helper(data_wide_csd, fn_score_mean("ztr_rc_us"), replications)
)
reliabilities = reliabilities.permutations %>% 
  summarise(across(.fns=list(m = fnFishZ, sd = ~ fnFishZ(.x, fn=sd),
                             CI95.lo = ~ fnFishZ(.x, fn=quantile, probs=.025),
                             CI95.hi = ~ fnFishZ(.x, fn=quantile, probs=.975)
                             #TODO check m against OP5 correction by Shieh (2010; https://doi.org/10.3758/BRM.42.4.906), implemented in AATtools::cormean
                             ),
            .cols=everything(), .names="{.col}_x_{.fn}")) %>% 
  pivot_longer(cols=everything()) %>% separate(col=name, into=c("method", "metric"), sep="_x_") %>% 
  pivot_wider(names_from = "metric", id_cols = "method") %>% arrange(desc(m)) %>% 
  separate(method, into=c("transformation", "range_cor"), sep="_rc_", fill="right", remove=F) %>% 
  mutate(range_cor = range_cor %>% replace_na("none")) %>% 
  group_by(transformation) %>% mutate(rank_rc = rank(-m)) %>% ungroup() %>% 
  group_by(range_cor) %>% mutate(rank_trans = rank(-m)) %>% ungroup()

reliabilities #overall descending

reliabilities %>% summarise(mean_rank = rank_rc %>% mean(), .by=range_cor)
#reliabilities %>% arrange(transformation, rank_rc)

reliabilities %>% summarise(mean_rank = rank_trans %>% mean(), .by=transformation) %>% arrange(mean_rank)
reliabilities %>% filter(range_cor=="none") %>% arrange(rank_trans)
```

``` {r effect size}
# test = with(data_long %>% filter(stimulus=="csd") %>% 
#     group_by(transformation, range_cor, id) %>% summarise(scr = mean(scr)), effsize::cohen.d(scr, NA, hedges.correction=T)) #check returned data format

effects = data_long %>% filter(stimulus=="csd") %>% 
  group_by(transformation, range_cor, id) %>% summarise(scr = mean(scr)) %>% #subject-level aggregates for correct between SD calculation
           #TODO 
           # - calculate the Cohen's d (effect variable) by calculating it exactly as the original formula using the t statistic
           # - reasonably rename variables 
  summarise(cohen_d = mean(scr, na.rm=T)/sd(scr, na.rm=T), #checked against apa::cohens_d(scr)
                   #d_apa = apa::cohens_d(scr),
                   #d_effsize = effsize::cohen.d(scr, NA)$estimate,
                   helper = apa::t_test(scr) %>% apa::t_apa(es_ci=T, print=F) %>% gsub("\\[", ";", .) %>% gsub("\\]", "", .),
                   n = scr %>% na.omit() %>% length(),
                   hedges_g = cohen_d * (1 - (3 / (4 * (n-1) - 1))), #for one-sample & within: df = N - 1 (for between: df = N - 2) [see Cumming (2011) p. 294; https://doi.org/10.4324/9780203807002]
                   # hedges_g_betweenDF = cohen_d * (1 - (3 / (4 * (n-2) - 1))),
                   # hedges_g2 = effsize::cohen.d(scr, NA, hedges.correction=T)$estimate,
                   # check = hedges_g == hedges_g2,
                   # check2 = hedges_g_betweenDF == hedges_g2,
                   effect = hedges_g) %>% 
  tidyr::separate_wider_delim(helper, delim=";", names=c(NA, "CI95.lo", "CI95.hi")) %>% mutate(across(contains("CI"), as.numeric)) %>% #note: effect size estimate is biased => Hedge's g but CI around Cohen's d is unbiased [see Cumming (2011) p. 305; https://doi.org/10.4324/9780203807002]
  group_by(transformation) %>% mutate(rank_rc = rank(-effect)) %>% ungroup() %>% 
  group_by(range_cor) %>% mutate(rank_trans = rank(-effect)) %>% ungroup() %>% 
  arrange(desc(effect))

effects

effects %>% summarise(mean_rank = rank_trans %>% mean(), .by=transformation) %>% arrange(mean_rank)
effects %>% summarise(mean_rank = rank_rc %>% mean(), .by=range_cor) %>% arrange(mean_rank)
```

``` {r export data multiverse}
data_multiverse = effects %>% select(-contains("rank")) %>% rename_with(function(x) paste0("effect_", x), .cols=contains("CI")) %>% 
  full_join(reliabilities %>% rename(rel = m) %>% select(transformation, range_cor, rel, contains("CI")) %>% rename_with(function(x) paste0("rel_", x), .cols=contains("CI")))
data_multiverse %>% write_rds(paste0(data_of_interest, "_multiverse.rds") %>% paste0("data/", .))

```
