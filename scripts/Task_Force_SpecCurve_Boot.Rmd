---
title: "Bootstrapping the Merz data set"
author: "Maren KlingelhÃ¶fer-Jens"
date: "2024-05-13"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(haven)
#library(MASS) #don't load MASS to not override dplyr::select
library(splithalfr)
#library(effsize)
#library(esci)
library(tidyverse)
library(patchwork)
```

```{r helpers}

reliability_helper = function(data, fn_score, replications, #need to be specified
                              participants="id", stratification=NULL, #constant for one data set
                              fn_coef=splithalfr::spearman_brown, ncores=parallel::detectCores() - 1, careful=F, verbose=F) #sensible defaults
{
  if (stratification %>% is.null() == F) stratification = data[,stratification] #data %>% pull(!!stratification)
  splithalfr::by_split(data=data, fn_score=fn_score, replications=replications,
                       participants = data[,participants], #data %>% pull(!!participants), 
                       stratification = stratification,
                       ncores=ncores, careful=careful, verbose=verbose) %>% 
    splithalfr::split_coefs(fn_coef=fn_coef)
}

fn_score_mean = function(column, na.rm=T) { #idea: create a function that
  return(function(df) { #returns another function 
    #with specifications (column & na.rm) from the parent-function => parameter df gets filled inside by_split function call
    #note: this would not be needed if by_split had a "..." argument that gets passed into fn_score
    
    #return(df %>% pull(!!column) %>% mean(na.rm=na.rm)) #requires library(tidyverse) for parallel (inefficient)
    return(mean(dplyr::pull(df, !!column), na.rm=na.rm)) #call dplyr::pull explicitly to not having to load tidyverse (or dplyr)
  })
}

```


```{r import-triallevel-data}

data_long <- readRDS("data/Merz_transformations.rds")

```


```{r bootstrapping-calc-rel-es}

#### Start the bootstrapping
# sampling with replacement

# Number of iterations: How often should the subjects be sampled?
n_iter <- c(1:2)

# Store ids in a variable
id_data <- unique(data_long$id)

# Sample size of bootstrap sample: How many participants should each bootstrapping sample contain?
sample_size_boot <- 30

################################## START THE LOOP

for (i in unique(n_iter)) {
  

# Select id's randomly
id_select <- sample(id_data, sample_size_boot, replace = TRUE)

# Select the data
data_select <- data_long[is.element(data_long$id, id_select), ]


#######################################################

#### Main Calculations for Multiverse

####################################################### RELIABILITY

#checks
data_long %>% summarise(trials = max(trialnr), .by = stimulus)
#data_long %>% group_by(stimulus, id) %>% summarise(trials = n()) %>% summarise(trials = mean(trials))

#reliability cs difference
data_wide_csd = data_long %>% filter(stimulus=="csd") %>% 
  mutate(condition = paste(transformation, range_cor, sep="_"),
                                 condition = condition %>% gsub("_none", "", .) %>% gsub("_", "_rc_", .)) %>% 
  pivot_wider(names_from=condition, values_from=scr, id_cols=c(id, trialnr, stimulus))

replications = 1000
set.seed(6723094)
reliabilities.permutations = tibble(
  raw = reliability_helper(data_wide_csd, fn_score_mean("raw"), replications),
  log = reliability_helper(data_wide_csd, fn_score_mean("log"), replications),
  sqr = reliability_helper(data_wide_csd, fn_score_mean("sqr"), replications),
  box = reliability_helper(data_wide_csd, fn_score_mean("box"), replications),
  ztr = reliability_helper(data_wide_csd, fn_score_mean("ztr"), replications),
  
  raw_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("raw_rc_cs"), replications),
  log_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("log_rc_cs"), replications),
  sqr_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("sqr_rc_cs"), replications),
  box_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("box_rc_cs"), replications),
  ztr_rc_cs = reliability_helper(data_wide_csd, fn_score_mean("ztr_rc_cs"), replications),
  
  raw_rc_us = reliability_helper(data_wide_csd, fn_score_mean("raw_rc_us"), replications),
  log_rc_us = reliability_helper(data_wide_csd, fn_score_mean("log_rc_us"), replications),
  sqr_rc_us = reliability_helper(data_wide_csd, fn_score_mean("sqr_rc_us"), replications),
  box_rc_us = reliability_helper(data_wide_csd, fn_score_mean("box_rc_us"), replications),
  ztr_rc_us = reliability_helper(data_wide_csd, fn_score_mean("ztr_rc_us"), replications)
)
reliabilities = reliabilities.permutations %>% 
  summarise(across(.fns=list(m = fnFishZ, sd = ~ fnFishZ(.x, fn=sd),
                             CI95.lo = ~ fnFishZ(.x, fn=quantile, probs=.025),
                             CI95.hi = ~ fnFishZ(.x, fn=quantile, probs=.975)
                             #TODO check m against OP5 correction by Shieh (2010; https://doi.org/10.3758/BRM.42.4.906), implemented in AATtools::cormean
                             ),
            .cols=everything(), .names="{.col}_x_{.fn}")) %>% 
  pivot_longer(cols=everything()) %>% separate(col=name, into=c("method", "metric"), sep="_x_") %>% 
  pivot_wider(names_from = "metric", id_cols = "method") %>% arrange(desc(m)) %>% 
  separate(method, into=c("transformation", "range_cor"), sep="_rc_", fill="right", remove=F) %>% 
  mutate(range_cor = range_cor %>% replace_na("none")) %>% 
  group_by(transformation) %>% mutate(rank_rc = rank(-m)) %>% ungroup() %>% 
  group_by(range_cor) %>% mutate(rank_trans = rank(-m)) %>% ungroup()

reliabilities #overall descending

reliabilities %>% summarise(mean_rank = rank_rc %>% mean(), .by=range_cor)
#reliabilities %>% arrange(transformation, rank_rc)

reliabilities %>% summarise(mean_rank = rank_trans %>% mean(), .by=transformation) %>% arrange(mean_rank)
reliabilities %>% filter(range_cor=="none") %>% arrange(rank_trans)


# Name the subset
assign(paste0("reliabilities_", i), reliabilities)

########################################################################### EFFECT SIZE

# test = with(data_long %>% filter(stimulus=="csd") %>% 
#     group_by(transformation, range_cor, id) %>% summarise(scr = mean(scr)), effsize::cohen.d(scr, NA, hedges.correction=T)) #check returned data format

effects = data_long %>% filter(stimulus=="csd") %>% 
  group_by(transformation, range_cor, id) %>% summarise(scr = mean(scr)) %>% #subject-level aggregates for correct between SD calculation
           #TODO 
           # - calculate the Cohen's d (effect variable) by calculating it exactly as the original formula using the t statistic
           # - reasonably rename variables 
  summarise(cohen_d = mean(scr, na.rm=T)/sd(scr, na.rm=T), #checked against apa::cohens_d(scr)
                   #d_apa = apa::cohens_d(scr),
                   #d_effsize = effsize::cohen.d(scr, NA)$estimate,
                   helper = apa::t_test(scr) %>% apa::t_apa(es_ci=T, print=F) %>% gsub("\\[", ";", .) %>% gsub("\\]", "", .),
                   n = scr %>% na.omit() %>% length(),
                   hedges_g = cohen_d * (1 - (3 / (4 * (n-1) - 1))), #for one-sample & within: df = N - 1 (for between: df = N - 2) [see Cumming (2011) p. 294; https://doi.org/10.4324/9780203807002]
                   # hedges_g_betweenDF = cohen_d * (1 - (3 / (4 * (n-2) - 1))),
                   # hedges_g2 = effsize::cohen.d(scr, NA, hedges.correction=T)$estimate,
                   # check = hedges_g == hedges_g2,
                   # check2 = hedges_g_betweenDF == hedges_g2,
                   effect = hedges_g) %>% 
  tidyr::separate_wider_delim(helper, delim=";", names=c(NA, "CI95.lo", "CI95.hi")) %>% mutate(across(contains("CI"), as.numeric)) %>% #note: effect size estimate is biased => Hedge's g but CI around Cohen's d is unbiased [see Cumming (2011) p. 305; https://doi.org/10.4324/9780203807002]
  group_by(transformation) %>% mutate(rank_rc = rank(-effect)) %>% ungroup() %>% 
  group_by(range_cor) %>% mutate(rank_trans = rank(-effect)) %>% ungroup() %>% 
  arrange(desc(effect))

effects

effects %>% summarise(mean_rank = rank_trans %>% mean(), .by=transformation) %>% arrange(mean_rank)
effects %>% summarise(mean_rank = rank_rc %>% mean(), .by=range_cor) %>% arrange(mean_rank)

# Name the subset
assign(paste0("effects_", i), effects)

# Delete for safety reasons
rm(id_select, data_select, effects, reliabilities)

}

```

``` {r combine-data}

### List all data subsets in a list and combine the subsets in one data frame
# Reliability
pattern_rel <- grep("reliabilities_",names(.GlobalEnv),value=TRUE)
pattern_rel_list <- do.call("list",mget(pattern_rel))
data_multi_rel <- bind_rows(pattern_rel_list)

# Effect sizes
pattern_es <- grep("effects_",names(.GlobalEnv),value=TRUE)
pattern_es_list <- do.call("list",mget(pattern_es))
data_multi_es <- bind_rows(pattern_es_list)

```



# Visualization
### Specification curve for regular pairwise t-test

```{r plot-settings}

# set colors for plotting
# set colors
clrs <- c("#D1D646",
"#F97068",
"#57C4E5",
"#17A398",
"#A05C7B",
"#435058")
barplot(1:6, col=clrs)
# set sizes 
size_point <- 5  # lines in categories under spec curve
size_text  <- 12 # text and ticks on x and y axis

fig_w <- 10
fig_h <- 7
fig_res <- 300

```


```{r plot-curves-effect-size}

# WITHOUT BOXCOX TRANSFORMATION TO DIFFERENTIATE OTHER TRANSFORMATIONS BETTER
data_multi_es = data_multi_es %>% filter(transformation != "box")

# Add index to order by effect size
# We have n + 1 unique approaches
data_multi_es$approach_num <-  1:nrow(data_multi_es)
data_multi_es[order(data_multi_es$effect),'approach_eff_order'] <-  1:nrow(data_multi_es)

# Factorize some variables

# labels
x_lab <- 'Approaches ordered by effect size'
y_lab <- 'Effect size (Hedge\'s g)'

# Order by effect size
# Colored by approach
p_effect <- data_multi_es %>%
  ggplot(aes(x = approach_eff_order, y = effect, color = transformation)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI95.lo, ymax = CI95.hi)) +
  scale_color_manual(name = 'Transformation', values = clrs[c(1:5)], labels = c("none", #"box-cox", 
                                                                                "log-transformed", 
  "square-root", "z-transformed")) +
  #scale_x_continuous(breaks = c(1:15), labels = c(1:15)) +
  theme_classic() +
  theme(text = element_text(size=size_text),
        legend.position = 'top') +
  xlab(x_lab) +
  ylab(y_lab) + 
  guides(color = guide_legend(nrow = 1))


# plot specifications of parameters
s_effect <- ggplot(data_multi_es, aes(x = approach_eff_order, y = range_cor)) +
  geom_point(shape = '|', size = size_point) +
   #scale_color_manual(values = rep('black', length(levels(res_ttest_d$approach)) )) +
  scale_y_discrete(name = 'Range correction', labels = c("none", "CS corrected", "US corrected")) +
  scale_x_continuous(breaks = c(1:15), labels = c(1:15)) +
  theme(axis.text.x = element_blank(),
        axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        panel.background = element_blank(),
        legend.position = 'none') +
  theme(text = element_text(size=size_text)) 

# Combine plots

plot_spec_effect <- p_effect / s_effect
plot_spec_effect

```



```{r plot-curves-reliability}

# Add index to order by size of reliability
# We have n + 1 unique approaches
data_multi_rel$approach_num <-  1:nrow(data_multi_rel)
data_multi_rel[order(data_multi_rel$m),'approach_rel_order'] <-  1:nrow(data_multi_rel)

# labels
x_lab <- 'Approach number ordered by size of reliability'
y_lab <- 'Reliability (split-half)'

# Order by size of reliability
# Colored by approach
p_reliability <- data_multi_rel %>%
  ggplot(aes(x = approach_rel_order, y = m, color = transformation)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI95.lo, ymax = CI95.hi)) +
  scale_color_manual(name = 'Transformation', values = clrs[c(1:5)], labels = c("none", "box-cox", "log-transformed", 
  "square-root", "z-transformed")) +
  #scale_x_continuous(breaks = c(1:15), labels = c(1:15)) +
  theme_classic() +
  theme(text = element_text(size=size_text),
        legend.position = 'top') +
  xlab(x_lab) +
  ylab(y_lab) + 
  guides(color = guide_legend(nrow = 1))


# plot specifications of parameters
s_reliability <- ggplot(data_multi_rel, aes(x = approach_rel_order, y = range_cor)) +
  geom_point(shape = '|', size = size_point) +
   #scale_color_manual(values = rep('black', length(levels(res_ttest_d$approach)) )) +
  scale_y_discrete(name = 'Range correction', labels = c("none", "CS corrected", "US corrected")) +
    #scale_x_continuous(breaks = c(1:15), labels = c(1:15)) +
  theme(axis.text.x = element_blank(),
        axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        panel.background = element_blank(),
        legend.position = 'none') +
  theme(text = element_text(size=size_text)) 

# Combine plots

plot_spec_reliability <- p_reliability / s_reliability
plot_spec_reliability

```


```{r plot-curves-effect-size-lines-only}

# labels
x_lab <- 'Approach number ordered by effect size'
y_lab <- 'Effect size (Hedge\'s g)'

# order by effect size

p_effect <- data_multi_es %>%
  ggplot(aes(x = approach_eff_order, y = effect)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI95.lo, ymax = CI95.hi)) +

  scale_x_continuous(breaks = c(1:15), labels = c(1:15)) +
  theme_classic() +
  theme(text = element_text(size=size_text),
        legend.position = 'top') +
  xlab(x_lab) +
  ylab(y_lab) + 
  guides(color = guide_legend(nrow = 1))


# plot specifications of parameters: transformation type
s_effect_1 <- ggplot(data_multi_es, aes(x = approach_eff_order, y = transformation)) +
  geom_point(shape = '|', size = size_point) +
  scale_x_continuous(breaks = c(1:15), labels = c(1:15)) +
  theme(axis.text.x = element_blank(),
        axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        panel.background = element_blank(),
        legend.position = 'none') +
  theme(text = element_text(size=size_text)) 


# plot specifications of parameters: range correction type
s_effect_2 <- ggplot(data_multi_es, aes(x = approach_eff_order, y = range_cor)) +
  geom_point(shape = '|', size = size_point) +
  scale_y_discrete(name = 'Range correction', labels = c("none", "CS corrected", "US corrected")) +
  scale_x_continuous(breaks = c(1:15), labels = c(1:15)) +
  theme(axis.text.x = element_blank(),
        axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        panel.background = element_blank(),
        legend.position = 'none') +
  theme(text = element_text(size=size_text)) 

# Combine plots

plot_spec_effect_lines_only <- p_effect / s_effect_1 / s_effect_2
plot_spec_effect_lines_only

```


